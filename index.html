<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>The Court Rules in Favor <Of class=""></Of></title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/main.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>

      <header>
        <h1>The Court Rules in Favor Of...</h1>
        <p>A CS109 Fall 2015 Final Project</p>
      </header>

      <div id="banner">
        <span id="logo"></span>

        <a href="http://arroyobrian.github.io/idvsus/" class="button fork"><strong>View On GitHub</strong></a>
        <div class="downloads">
          <span>Downloads:</span>
          <ul>
            <li><a href="https://github.com/arroyobrian/idvsus/zipball/master" class="button">ZIP</a></li>
            <li><a href="https://github.com/arroyobrian/idvsus/tarball/master" class="button">TAR</a></li>
          </ul>
        </div>
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        <h1>
<a id="welcome-to-pages" class="anchor" href="#welcome-to-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Video</h1>

<p>Here is a 2 minute screencast describing our project:</p>

<iframe width="560" height="315" src="https://www.youtube.com/watch?v=LzVc2Lh98Ns" frameborder="0" allowfullscreen></iframe>

<h2>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Motivation and Background</h2>

<p>The comments made by Supreme Court justices often carry a lot of weight over public opinion. For example, Justice Antonin Scalia’s recent comments about affirmative action have attracted major media attention. For our final project, we wanted to see how effectively we can predict the court rulings based on the words used by the justices and attorneys in the courtroom. </p>

<p>We want to predict the outcome Supreme Court decisions using oral argument transcripts. Studies in linguistics and psychology, as well as common sense, dictates that the word choices that people make convey crucial information about their beliefs and intentions with regard to issues. Rather than use precedents or formal analysis of the law to predict Supreme Court decisions, we attempt to extract essential emotional features of oral arguments made by justices and advocates in the court.

Through this project, we sought to answer three primary questions:
<ul>
  <li>How does natural language processing on oral arguments help us predict the outcomes of Supreme court decisions?</li>
  <li>Which features of oral arguments would best help us do this? (number of words uttered by justices, sentiments of words, or others)?</li>
  <li>Which approach would yield better results - latent semantic indexing or sentiment analysis?</li>
</ul>
</p>

<h2>
<a id="what-will-code-look-like" class="anchor" href="#what-will-code-look-like" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview of Methodology</h2>

<p>One natural language processing method is to analyze the sentiments expressed. Analyzing sentiment is commonly used to capture public opinion in social media outlets such as Twitter and Yelp, for example. The Supreme Court releases transcripts of court proceedings the day before each verdict. We collected all the transcripts from 2000 to 2014, and extracteddescriptive words from each transcript to make predictions based on the word list. These words vary from “improper” to “negligent” to “precise” to “straightforward”. 
</p>

<p>However, our method of capturing sentiment only accurately predicted about 55% of the court cases. In a way, the relatively low accuracy actually makes sense because the language used inside courtrooms are very legalistic and emotions don’t typically play a big role.
</p>

<p>Subsequently, we conducted Justice-centered data analysis (without NLP) as our baseline model, before delving into 2 different approaches to NLP - Latent Semantic Indexing and Sentiment Analysis - to see if these datasets and insights gleaned from them would provide valuable insight and help supplement our model. The analysis of baseline and 2 NLP methods are detailed below.
</p>




<h2>
<a id="what-will-code-look-like" class="anchor" href="#what-will-code-look-like" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Sources</h2>

<p>TWe used several sources of data in our analysis. For the SVM, Decision Trees, and Random Forest Classifiers we used a database that recorded Supreme Court decisions that date back to 1946 until 2014. For the Latent Semantic Indexing, we used PDFs of transcripts of Supreme Court Decisions dating from 2000, which were converted into plain text files. We supplanted this with the same database we used for the classifier to retrieve the decisions of the court cases. Sentiment Analysis also used the same data as LSI, but generated features slightly differently.</p>

<h2>
<a id="whos-this-matt-graham" class="anchor" href="#whos-this-matt-graham" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analysis: Justice-Centered Data
</h2>

<p>The justice-centered data is very robust, with over 6000 rows of data. Most importantly, extracting proper features from the dataset proved to be most insightful. The process for the above was arduous as the domain knowledge for the group was initially low. We used supplements such as the Supreme Court website and Wikipedia to learn more about the court and the proceedings that occur. Moreover, the process of running models over again with different variables was avoided after realizing the dataset contained many variable that were outcome dependent. Moreover, many variables were very consistent among data that we removed it as a new change in those variables can ruin accuracy on our models. For instance, the chiefJustice variable is a variable that can be used but ought not to be as a new the chief justice can be hard to account for in modern times. </p>


<h2>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analysis: Latent Semantic Indexing</h2>

<p>LSI is a method that first calculates the frequency of a word, penalizing it if it appears in many other documents. After producing a matrix of word frequencies by document, a decomposition of this matrix yields three other matrices: one that represents the prevalence of a certain “theme” in a document, another that represents the importance of the theme across all documents, and another that represents the importance of each word in any given theme.

Separating the document by the words Petitioners and Respondents spoke, one can generate two sets of these matrices, and run logistic regression on the difference between the two (as to show the difference between the topics each party put emphasis on during the case). This yielded an accuracy of 65.1% on test data.</p>

<h2>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analysis: Sentiment Analysis</h2>



<p>Sentiment Analysis traditionally assigns a positive or negative score to different words, assigns an overall score to some portion of the text, and runs logistic regression on those portions of the text. We had several features we considered (for each the petitioners and respondent parties): The total number of words judges spoke to each attorney, the sentiment score of the speeches of each party, and the number of times that any judge interrupts the part. We then ran logistic regression on these features, yielding an accuracy of about 63.6% on test data.</p>

<h2>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>


<p>What this project has taught us is that while it may be easier to extract meaningful predictions from simpler messages such as tweets and movie reviews, something as complicated as the minds of supreme court justices are more difficult to predict. There is still a lot more room for improvement for machines can better understand human thoughts through language.</p>

      </section>
      <footer>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
