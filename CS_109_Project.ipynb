{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS109 Project - The Court Rules In Favor Of...\n",
    "## Aidi Adnan Brian John (Team AABJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "The purpose of this project is to predict votes of Supreme Court justices using oral argument transcripts. Studies in linguistics and psychology, as well as common sense, dictates that the word choices that people make convey crucial information about their beliefs and intentions with regard to issues. Rather than use precedents or formal analysis of the law to predict Supreme Court decisions, we attempt to extract essential emotional features of oral arguments made by justices and advocates in the court. Using aggregate data from 1946 to present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Oral Argument Transcripts - obtained from http://www.supremecourt.gov/oral_arguments/argument_transcript.aspx. Transcripts are made available on the day of court hearing.\n",
    "Justice Vote Counts/Case Information - obtained from the Supreme Court Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Table of Contents\n",
    "* [The Court Rules in Favor Of...](#CS109 Project - The Court Rules In Favor Of...)\n",
    "    * [1. Data Cleaning and Preparation](#1.-Data-Cleaning-and-Preparation)\n",
    "    * [2. Latent Sentiment Indexing](#2.-LSI-:-Latent-Sentiment-Indexing)\n",
    "        * [2.0.1 Pre-processing](##Stage-1:-Pre-processing)\n",
    "        * [2.0.2 Frequency Document-Inverse Document Frequency (TF-IDF)](###-TF-IDF-:-Frequency-Document-Inverse-Document Frequency)\n",
    "        * [2.1 Splitting prepared documents into petitioner and respondent speeches](##-2.1-Splitting-prepared-documents-into-petitioner-and-respondent-speeches)\n",
    "        * [2.2 Applying term-frequency inverse document frequency vectorizer](##-2.2-Applying-term-frequency-inverse-document-frequency-vectorizer)\n",
    "        * [2.3 Running Singular Vector Decomposition](##-2.3-Running-Singular-Vector-Decomposition)\n",
    "        * [2.4 Training logistic regression classifier on petitioner and respondent differences](##-2.4-Training logistic-regression-classifier-on-petitioner-and-respondent-differences)\n",
    "    * [Sentiment Analysis](#-3.-Sentiment-Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a python script (scraper.py) to first scrape the pdfs from the Supreme Court Justice Website (but didn't upload those to the repository, because we ultimately wanted to use text files in our process). We then used a script to convert the pdf files to text files, but not before removing the last 10 pages from each transcript, which were reserved as an index for certain words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gather all txt files, first get the path to the data directory\n",
    "# then list the files and filter out all non-txt files\n",
    "curPath = os.getcwd()\n",
    "dataPath = curPath + '/data/'\n",
    "fileList = os.listdir(dataPath)\n",
    "fileExt = \".txt\"\n",
    "txtFiles = filter(lambda f : f[-4:] == fileExt, fileList)\n",
    "txtFiles = map(lambda f : dataPath + f, txtFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAllRawText(txtFiles):\n",
    "    '''\n",
    "    Inputs:\n",
    "    txtFiles: a list of paths of textfiles\n",
    "    \n",
    "    Returns:\n",
    "    list of all uncleaned transcripts in raw text form.\n",
    "    '''\n",
    "    return [(open(txtFiles[i]).read()) for i in range(len(txtFiles))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_dict(fileList, fileExt='.txt'):\n",
    "    '''\n",
    "    This function takes the fileList and returns a list of dictionaries of the format \n",
    "    {'case_number': case_number, 'full_text': full_text}\n",
    "    \n",
    "    Inputs:\n",
    "    fileList: list of the paths of the textfiles\n",
    "    fileExt: optional parameter for the type of file\n",
    "    \n",
    "    Returns:\n",
    "    dictionary of the filename:text\n",
    "    '''\n",
    "    fileDict=[]\n",
    "    fields=['docket', 'full_text']\n",
    "    txtFiles_filter = filter(lambda f : f[-4:] == fileExt, fileList)\n",
    "    for each in txtFiles_filter:\n",
    "        name_str=each[4:-4]\n",
    "        try:\n",
    "            indexx=name_str.index('_')\n",
    "            docketNum=name_str[:indexx]\n",
    "        except ValueError:\n",
    "            docketNum=name_str\n",
    "        cur = open(dataPath+each)\n",
    "        textual = cur.read()\n",
    "        cur.close()\n",
    "        tuple_=(docketNum, textual)\n",
    "        fileDict.append(dict(zip(fields, tuple_)))\n",
    "    return fileDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote a parser to extract the names of the petitioner and respondant attorneys from the first 2 pages of the converted text document. An example of list of petitioner and respondant speakers, taken from the example case in 2014 of Johnson v United States (docket number 13-7120) is:\n",
    "\n",
    "Katherine M. Menendez, ESQ., Minneapolis, Minn.; on behalf of Petitioner\n",
    "Michael R. Dreeben, ESQ., Deputy Solicitor General, Department of Justice, Washington D.C.; on behalf of Respondent\n",
    "\n",
    "To get these speakers, we write a function that uses a regular expression to split the lines based on new line and checks whether there is a name in the line. If we find a name, then we check if that name was listed as a petitoner or respondent at the beginning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_petitioners_and_respondents(text):\n",
    "    '''\n",
    "    Inputs:\n",
    "    text : a transcript in its raw form, without having run cleanTextMaker\n",
    "\n",
    "    Returns:\n",
    "    pet_speakers, res_speakers, other_speakers\n",
    "    the petitoner speakers, the respondent speakers, and any other speakers as a list\n",
    "    '''\n",
    "    #get portion of transcript between APPEARANCES and CONTENTS that specifies speakers for petitioners/respondents\n",
    "    start = text.find('APPEARANCES:') + len('APPEARNACES')\n",
    "    end = text.find('C O N T E N T S')\n",
    "    speakers_text = text[start:end]\n",
    "    split_speakers_text = re.split('\\.[ ]*\\n', speakers_text)\n",
    "    #for each speaker, get name (capitalized) and side (Pet/Res) he/she is speaking for\n",
    "    pet_speakers, res_speakers, other_speakers = [], [], []\n",
    "    for speaker in split_speakers_text:\n",
    "        name = speaker.strip().split(',')[0]\n",
    "        #search for first index of capitalized word (which will be start of speaker name)\n",
    "        start = 0\n",
    "        for idx, char in enumerate(name):\n",
    "            if str.isupper(char):\n",
    "                start = idx\n",
    "                break\n",
    "        #actual name to be appended to correct list\n",
    "        name = name[start:]\n",
    "        \n",
    "        #if words Petition, Plaintiff, etc occur in speaker blurb, speaker belongs to Pet\n",
    "        if any(x in speaker for x in ['etition' , 'ppellant', 'emand', 'evers', 'laintiff']):\n",
    "            pet_speakers.append(name)\n",
    "        #otherwise if words Respondent, Defendant, etc occur, speaker belongs to Res\n",
    "        elif any(x in speaker for x in ['espond' , 'ppellee', 'efendant']):\n",
    "            res_speakers.append(name)\n",
    "        #otherwise if neither side is specified in blurb, speaking belongs to Other\n",
    "        elif 'neither' in speaker:\n",
    "            other_speakers.append(name)\n",
    "    return pet_speakers, res_speakers, other_speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function used to generate a regular expression for later use based on \"TITLE. LASTNAME\"; however, that pattern ultimately ended up not being used in some of the cases, and we abandonded this format in favor of just using the last name to generate the regular expression that we would ultimately use to separate the text into which speaker was responsible for a portion of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateRES(nameList, plebe):\n",
    "    \"\"\"\n",
    "    generates a regular expression that splits text based on speaker names\n",
    "    \n",
    "    Inputs:\n",
    "    nameList: a list of strings of the names\n",
    "    plebe: a boolean determining whether or not the list is of justices or not\n",
    "    \n",
    "    Returns:\n",
    "    A list of regular expressions for each of the names that work for supreme\n",
    "    court case transcripts\n",
    "    \"\"\"\n",
    "    retList = []\n",
    "    for name in nameList:\n",
    "        address = \"\"\n",
    "        if plebe:\n",
    "            words = name.split(' ')\n",
    "            # first term is the title, last\n",
    "            # word is the last name\n",
    "            address = words[-1]\n",
    "            retList.append(address)\n",
    "        else:\n",
    "            # Justice can appear in two ways!\n",
    "            address = \"JUSTICE %s\" % name\n",
    "            address2 = \"CHIEF JUSTICE %s\" % name\n",
    "            retList.append(address)\n",
    "            retList.append(address2)\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't yet have a way to gather the names of the Justices from the text, so we do so! We just find the word JUSTICE in all caps and then gather whatever comes after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getJusticeNames(text):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    text is the raw text of a transcript\n",
    "    \n",
    "    Returns:\n",
    "    A set of the names of Justices mentioned by name in the transcript\n",
    "    \"\"\"\n",
    "    index = 0\n",
    "    retList = []\n",
    "    while index < len(text):\n",
    "        index = text.find(\"JUSTICE\", index)\n",
    "        if index == -1:\n",
    "            break\n",
    "        index += 8 # because length of JUSTICE is 7, plus length of the space\n",
    "        prevIndex = index\n",
    "        while text[index] != ':':\n",
    "            index +=1\n",
    "        retList.append(text[prevIndex:index])\n",
    "    return list(set(retList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general flow of court proceedings is that the Petitioner attornies make their oral argument, followed by the Respondent attornies, before we hear the rebuttal argument of the Petitioners again. Throughout all proceedings, Justices are free to interject with questions and statements of their own. The below function extracts the main argument portion of the oral transcripts, which is the meat of the proceedings that we are interested in conducting analysis on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_argument_portion(text):\n",
    "    '''\n",
    "    Inputs:\n",
    "    Raw text of a transcript as a string\n",
    "    \n",
    "    Returns:\n",
    "    The argument portion of the case as a string\n",
    "    '''\n",
    "    #start and end defines bounds of argument portion of text\n",
    "    start = text.find('P R O C E E D I N G S')\n",
    "    end = text.rfind('Whereupon')\n",
    "    return text[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(s):\n",
    "    '''\n",
    "    Inputs:\n",
    "    s: string of words\n",
    "    \n",
    "    Returns:\n",
    "    An integer counting the number of the words in s\n",
    "    '''\n",
    "    s = s.split()\n",
    "    non_words = ['-', '--']\n",
    "    return sum([x not in non_words for x in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transcripts contain a lot of line numbers as well as linebreaks in between sentences, so we want to remove those before we try and do any analysis on them. We can also use this function to return a list of the cleaned version of our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanTextMaker(text):\n",
    "    '''\n",
    "    Inputs:\n",
    "    text: a raw text with newlines and numbers, as is usual in the transcripts\n",
    "    \n",
    "    Returns:\n",
    "    A file with newlines and numbers scrubbed\n",
    "    '''\n",
    "    text_arr=text.splitlines()\n",
    "    text_clean=[]\n",
    "    for each in text_arr:\n",
    "        if each != '':\n",
    "            try:\n",
    "                int(each)\n",
    "            except ValueError: #assummption: if the item only has integers, it is a line number.\n",
    "                text_clean.append(each)\n",
    "    out_text=' '.join(text_clean)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAllRawCleanText(txtFiles):\n",
    "    '''\n",
    "    Inputs:\n",
    "    txtFiles: a list of paths of textfiles\n",
    "    \n",
    "    Returns:\n",
    "    list of all cleaned transcripts in raw text form.\n",
    "    '''\n",
    "    return [(cleanTextMaker(open(txtFiles[i]).read())) for i in range(len(txtFiles))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be useful to split data into test and train sets, so lets write a function that does so for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitData(X, fraction_train=9.0 / 10.0):\n",
    "    \"\"\"\n",
    "    Deterministically splits a vector\n",
    "    \n",
    "    Inputs:\n",
    "    X: a one dimensional vector\n",
    "    fraction_train: the fraction of data that is desired to be train\n",
    "    \n",
    "    Returns:\n",
    "    the train portion and test portions of the vector\n",
    "    \"\"\"\n",
    "    end_train = int(len(X) * fraction_train)\n",
    "    X_train = X[0:end_train]\n",
    "    X_test = X[end_train:]\n",
    "    return X_train, X_test\n",
    "\n",
    "def splitTrainTest(X, Y, fraction_train = 9.0 / 10.0):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    X, Y : vectors to be split\n",
    "    \n",
    "    Returns:\n",
    "    Each vector split into train and test\n",
    "    \"\"\"\n",
    "    X_train, X_test = splitData(X, fraction_train)\n",
    "    Y_train, Y_test = splitData(Y, fraction_train)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSI : Latent Sentiment Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSI is a method that uses singular value decomposition to find patterns and themes between unstructured documents. The key idea behind LSI is to select the conceptual content of some text by finding connections between terms that occur in similar contexts. Once we produce a SVD, we can also truncate the resultant matricies to instead produce smaller matricies that are easier to handle and more likely to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document representation is the first step of our analysis since there are a variety of ways to represent a transcript, which in its raw form is a simple string of texts. We use a pre-processing technique that reduces the complexity of the documents and makes them easier to handle, which is to transform the oral transcripts from the full text version to a document vector/sparse matrix. Every text document is represented as a vector of term weights (word features) from a set of terms (dictionary), where each term occurs at least once in a certain critical number of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High dimensionality of text representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A major characteristic of document classification problems is the extremely high dimensionality of data where the number of potential features often exceeds the number of training documents. Dimensionality reduction is thus critical to allow for efficient data manipulation. Irrelevant and redundant features often degrade performance of classification algorithms both in accuracy and speed, and also tends to fall into the all-common trap of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing of text data involves tokenization of raw text, stop words removal, stemming and eliminating as much as possible the language dependent factors. Brief explanations of these preprocessing stages are as fllows:\n",
    "\n",
    "1. Sentence splitting: identifying sentence boundaries in documents\n",
    "2. Tokenization: partitioning documents that are initially treated as a string into a list of tokens\n",
    "3. Stop word removal: removing common English words like \"the\", \"a\", etc\n",
    "4. Stemming: reducing derived words to its most root form, example happiest -> happy\n",
    "5. Noisy data: cleaning noisy data spilt over from pdf to text conversion, including inclusion of line numbers, page breaks, etc\n",
    "6. Text representation: determining whether we should use words, phrases or entire sentences as a \"token\" for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction vs. feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After feature extraction, feature selection was conducted to construct a vector space of appropriate dimensionality, which improves the scalability, efficiency and accuracy of our classification algorithm. The main idea of feature selection is to choose a subset of features from the original texts, with subset determined by obtaining features with the highest score according to some predetermined measure of feature importance.\n",
    "\n",
    "We use filters to generate our features. Filters can be conducted independently of the actual classification algorithm, and is not very computationally expensive. Filters use an evaluation metric that measures ability of a feature to differentiate each class, hence choosing the most discriminative and valuable features. The filter of our choice is a technique called frequency document-inverse document frequency, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF : Frequency Document-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency document–inverse document frequency (tf-idf), is a powerful method to evaluate how important is a word in a document, and captures the relative significance among words. It converts the textual representation of information into a Vector-Space Model or a sparse matrix representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used to generated tfidf sparse matricies for the importance of words in documents\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# internal utilities used to replicate functionality of truncated_svd\n",
    "from sklearn.utils import as_float_array\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "# stemmer of words\n",
    "import snowballstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allRawText = getAllRawText(txtFiles)\n",
    "allRawCleanText = getAllRawCleanText(txtFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the approach we took when generating the regular expressions for parsing, we want to have a way to convert the names scraped from the documents into a name that we can generally split the speechs by, and thus we adopt the convention of using the last name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toColloquialName(formal_name):\n",
    "    ret = formal_name.split()\n",
    "    return ret[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running LSI, we do not want to possibly split importance among words that are actually very similar (such as \"stealing\" and \"steal\"), so we stem words by removing the suffix, bring down the words to a root, or 'stem' that we can assign importance to. There was an issue with different encodings: the txt documents are stored in Latin1 encoding when converted from PDFs to permit earlier functions to work, but when iterating through words there is some issues with how the words are decoded and passed to the stemmer. As a result, we need to manually convert incompatible strings to a tractable format. This conversion was not possible on a single document in our entire database, so we ultimately had to remove it from our database (if we didn't remove it, there would be an issue when we used the docketId from the document to index into a merged dataframe later on, we would have one more response variable than predictor variables). Stemming naturally can leave words as a non english word, or may incorrectly mistem a word. Nothing short of a large dictionary containing the stem of every possible word would accurately perform the stemming, so we are forced to accept this aggressive trimming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def destem(allRawText):\n",
    "    \"\"\"\n",
    "    stems all words from a list of documents\n",
    "    documents are assumed to be stored in Latin1 encoding\n",
    "    there is one document that is not tractable so we exclude it\n",
    "    uses snowballstemmer\n",
    "    required to decode string to avoid UnicodeDecodeErrors\n",
    "    \n",
    "    Inputs:\n",
    "    a list of raw text files that have been cleaned\n",
    "    \n",
    "    Returns:\n",
    "    a list of text files that have been stemmed word by word\n",
    "    \"\"\"\n",
    "    stemmer = snowballstemmer.stemmer('english')\n",
    "    stemmedList = []\n",
    "    for text in allRawText:\n",
    "        try:\n",
    "            temp = stemmer.stemWords(text.split())\n",
    "            for i in xrange(len(temp)):\n",
    "                if str(type(temp[i])) == \"<type 'str'>\":\n",
    "                    temp[i] = temp[i].decode('Latin1')\n",
    "            res = ' '.join(temp)\n",
    "            stemmedList.append(res)\n",
    "        except UnicodeDecodeError:\n",
    "            # literally just one document\n",
    "            pass\n",
    "    return stemmedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcript cases on the first page have a number that yields the docket ID of the case. We can very easily retrieve the docket number by just performing a .find() on the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDocketNo(text):\n",
    "    '''\n",
    "    Input: the text of a transcript\n",
    "    \n",
    "    Returns:\n",
    "    the docket number of the case\n",
    "    '''\n",
    "    cleantext = cleanTextMaker(text)\n",
    "    docketIdx = cleantext.find(\"No.\")\n",
    "    return cleantext[docketIdx+4:].split()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to merge the text files with the supreme court database so that we can easily associate the text files with the docketId and get the decision of the cases. However, the supreme court database unfortunately does not contain information from beyond 2014, so we lose out on several transcripts in the merging process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(934, 54)\n"
     ]
    }
   ],
   "source": [
    "fileDict=get_file_dict(fileList)\n",
    "txtdf = pd.DataFrame(fileDict)\n",
    "casedf = pd.read_csv('supremeCourtDb.csv')\n",
    "merged = pd.merge(left=txtdf, right=casedf, how='inner', left_on='docket', right_on='docket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As referenced earlier, there is a single document that is not tractable to stemming due to codec issues, so we merely drop it for being insolent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop problematic docket\n",
    "merged = merged[merged.docket != '08-351']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(931, 54)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Splitting prepared documents into petitioner and respondent speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have about 930 documents to work with. We now want to find a way to gather the texts of what the petitioners and the respondents say. We adapt a function we wrote earlier that counted the number of words that each speaker said and use it to gather the texts that each party is responsible for. We first gather them by speaker then gather them by the group that they are a part of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitTextPetRes(text):\n",
    "    '''\n",
    "    Input: \n",
    "    text: raw text document (transcript, recently opened)\n",
    "        \n",
    "    Returns:\n",
    "    a dictionary of speaker: the words they said\n",
    "    a dictionary of group: the words they said\n",
    "    '''\n",
    "    arg_text = get_argument_portion(text)\n",
    "    #keeps track of current speaker\n",
    "    current_speaker = 'N/A'\n",
    "    clean_argument = cleanTextMaker(arg_text)\n",
    "\n",
    "    # first get the names of the judges and speakers\n",
    "    pet_speakers, res_speakers, _ = get_petitioners_and_respondents(text)\n",
    "    \n",
    "    # create the regular expression for the justices and the plebes\n",
    "    petList = generateRES(pet_speakers, True)\n",
    "    resList = generateRES(res_speakers, True)\n",
    "    petList = map(lambda name : name + \":\", petList)\n",
    "    resList = map(lambda name : name + \":\", resList)\n",
    "    all_speakers = (petList + resList)\n",
    "    \n",
    "    RE = '('  + '|'.join(all_speakers) + ')'\n",
    "    \n",
    "    # split argument portion by times elements in plebeList (e.x. MR. FARR: or EUGENE: appears)\n",
    "    split_argument = re.split(RE, clean_argument)\n",
    "    \n",
    "    # dictionary keyed by speaker, with value actual speech (in string format)\n",
    "    speech = dict(zip(all_speakers + [current_speaker], [\"\"] * (len(all_speakers)+1)))\n",
    "    \n",
    "    #iterate through split argument, accumulating speeches for all speakers\n",
    "    for s in split_argument:\n",
    "        if s in all_speakers:\n",
    "            current_speaker = s\n",
    "        #if split chunk is part of speech of current speaker, append to word count\n",
    "        else:\n",
    "            speech[current_speaker] += s\n",
    "\n",
    "    #combine all pet and res speakers, if multiple\n",
    "    retDict = {\"resSpeakers\":\"\", \"petSpeakers\":\"\"}\n",
    "    \n",
    "    for rSpeaker in resList:\n",
    "        retDict[\"resSpeakers\"] += speech[rSpeaker]\n",
    "    for pSpeaker in petList:\n",
    "        retDict[\"petSpeakers\"] += speech[pSpeaker]\n",
    "\n",
    "    return speech, retDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the transcripts are not consistently formatted, sometimes we fail to gather the names of petitioners or respondents. In this case, we do not want to add that case's speech to the database because then we wouldnt be able to compare either the respondents or the petitioners against an empty speech. Just would not be fair!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iterate through merged.full_text, trying to fill in merged.pet_speech and merged.res_speech\n",
    "allPetSpeeches = []\n",
    "allResSpeeches = []\n",
    "allDocketNo = []\n",
    "allDecisions = []\n",
    "for row in merged.iterrows():\n",
    "    speech, retDict = splitTextPetRes(row[1][\"full_text\"])\n",
    "    petSpeech = retDict[\"petSpeakers\"]\n",
    "    resSpeech = retDict[\"resSpeakers\"]\n",
    "    # if either petSpeech or resSpeech is an empty string, do not add to workable dataset\n",
    "    if petSpeech and resSpeech:\n",
    "        allPetSpeeches.append(petSpeech)\n",
    "        allResSpeeches.append(resSpeech)\n",
    "        allDocketNo.append(row[1][\"docket\"])\n",
    "        allDecisions.append(row[1][\"partyWinning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(886, 886, 886)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some oral transcripts have empty petitioner or respondent speeches due to dirty scraping of pdf files\n",
    "# for example, get_petitioners_and_respondents sometimes does not scrape properly due to bad formatting\n",
    "len(allPetSpeeches), len(allResSpeeches), len(allDecisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now stem all of the words in the document files. This takes a long time because of the inconsistent encodings of strings as mentioned earlier, necessitating iterating through each word and manually trying to convert it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# takes long to run\n",
    "allDestemmedPetSpeeches = destem(allPetSpeeches)\n",
    "allDestemmedResSpeeches = destem(allResSpeeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(886, 886)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allDestemmedPetSpeeches), len(allDestemmedResSpeeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Applying term-frequency inverse document frequency vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to pass each set of documents to the vectorizer that will count the number of words and assign them based on Term-Frequency Inverse Document Frequency (tfidf), which first calculates the raw term frequency (aka the number of times that the word appears in the document) and then multiplies it by the inverse document frequency (a global weighing function):\n",
    "$$g_i = \\log_2 \\frac{n}{1 + df_i}$$\n",
    "\n",
    "Where $g_i$ is the weight for term $i$, $n$ is the number of times a word appears in a document, and $df_i$ is the number of documents in which $i$ appears. This properly penalizes words that appear frequently in many documents. We take $g_i \\times f_i$ (where $f_i$ is the raw frequency) as the tfidf statistic for that word in a given document. \n",
    "\n",
    "(credit to: https://en.wikipedia.org/wiki/Latent_semantic_indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer1 = TfidfVectorizer(min_df=1, norm='l2', use_idf=True, stop_words='english', encoding='Latin1', analyzer='word', token_pattern='\\w+')\n",
    "vectorizer2 = TfidfVectorizer(min_df=1, norm='l2', use_idf=True, stop_words='english', encoding='Latin1', analyzer='word', token_pattern='\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Running Singular Vector Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD is a method to decompose a matrix into three other matricies that perform the following transformations: a rotation, a scaling along the coordinate axes, and another rotation. Respectively, we label these as T, S, DT in our code.\n",
    "\n",
    "When we run SVD on the matrix generated by the vectorizers, the 3 matricies we get back have a meaning in the context of LSI. The first matrix is a matrix that represents the themes in the documents, the second is a diagonal matrix of singular values representing the relative importance of each theme overall, and the third matrix is representing the importance of each word in the themes. We can run logistic regression on just the first matrix, and specifically the different between the matrix of the respondents and the petitioners, to represent the difference in how strongly the parties speak about a certain theme within a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runSVD(documentList, vizer, numComponents=25, nIter=5):\n",
    "    \"\"\"\n",
    "    takes a list of documents and a vectorizer\n",
    "    converts document list to a matrix of frequencies \n",
    "        (as determined by the vectorizer) of document by word\n",
    "    takes matrix and runs truncated SVD on it to generate\n",
    "    a matrix that consists of themes (T) in each document\n",
    "    overall importance of the word (S)\n",
    "    and a matrix that consists of how important each word\n",
    "    is in the theme (DT)\n",
    "    \n",
    "    this code is partially derived from sklearn's\n",
    "    truncated_svd function (which doesn't return\n",
    "    all of the matricies we are interested in)\n",
    "    \"\"\"\n",
    "    mat = vizer.fit_transform(documentList)\n",
    "    X = as_float_array(mat, copy=False)\n",
    "    # T is the term by concept matrix\n",
    "    # S the singular value matrix\n",
    "    # D is the concept-document matrix\n",
    "    T, S, DT = randomized_svd(X, numComponents, n_iter=nIter)\n",
    "    return T, S, DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tPet, sPet, dTPet = runSVD(allDestemmedPetSpeeches, vectorizer1, numComponents=25)\n",
    "tRes, sRes, dTRes = runSVD(allDestemmedResSpeeches, vectorizer2, numComponents=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((886, 25), (25,), (25, 29308))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print tPet.shape, sPet.shape, dTPet.shape\n",
    "print tRes.shape, sRes.shape, dTRes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Training logistic regression classifier on petitioner and respondent differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suggested earlier, we run logisitic regression on the difference of the two matricies that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run logistic regression on D x numTopics matrix of independent variables, vs. 0/1 result vector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, X, y, n_folds=5):\n",
    "    \"\"\"\n",
    "    From CS109's problem sets\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "    clf : an instance of a scikit-learn classifier\n",
    "    parameters: a parameter grid dictionary thats passed to GridSearchCV (see above)\n",
    "    X: a samples-features matrix in the scikit-learn style\n",
    "    y: the response vectors of 1s and 0s (+ives and -ives)\n",
    "    n_folds: the number of cross-validation folds (default 5)\n",
    "    score_func: a score function we might want to pass (default python None)\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    The best estimator from the GridSearchCV, after the GridSearchCV has been used to\n",
    "    fit the model.\n",
    "    \"\"\"\n",
    "    clf = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    clf.fit(X,y)\n",
    "    return clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression, our good old friend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clflog = LogisticRegression()\n",
    "tDiff = tPet - tRes\n",
    "xTrain, yTrain, xTest, yTest = splitTrainTest(tDiff, allDecisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clflogopt = cv_optimize(clflog, {\"C\": [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, xTrain, yTrain, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clflogopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692597239649 0.651685393258\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = clflogopt.score(xTrain, yTrain)\n",
    "test_accuracy = clflogopt.score(xTest, yTest)\n",
    "print training_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so maybe we are not at the point where we can replace judges just yet. However, there were some issues that may have hindered our accuracy. For example, we had to get rid of some documents when we were merging document texts with databases, because we didn't have data from decisions in 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above analysis, we have focused on parts of the oral transcripts corresponding to attorney speeches, which means we are essentially ignoring an equally valuable portion of information that we can glean from these transcripts: the judge's responses and questions to these attorneys. In this section, we attempt to conduct Natural Language Processing on judge's speeches and other salient features of the text that were not included in the Latent Semantic Analysis above, which might yield interesting results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter out all oral transcripts that do not discriminate between individual justice's speeches, instead using\n",
    "# QUESTION: in place of all justice's speeches\n",
    "qualifying_rows = []\n",
    "for rowNo in range(len(merged)):\n",
    "    # find appropriate row and check whether full_text contains QUESTION: - if so, delete from database\n",
    "    row = merged.iloc[rowNo, :]\n",
    "    if row[\"full_text\"].find(\"QUESTION:\") == -1:\n",
    "        qualifying_rows.append(rowNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mergedJudges = merged.iloc[qualifying_rows, :] \n",
    "mergedJudges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our cleaned dataframe with information about raw text and decisions for every oral transcript, we want to find the most appropriate features for predictors - we're on the stage of feature extraction again. After much experimentation and linguistical analysis on court proceedings in particular, we identified the following features that we want to introduce as predictors to run our classification algorithm on. \n",
    "\n",
    "For each oral transcript, we want to identify:\n",
    "1. Number of words judges uttered to petitioner's and respondent's sides:\n",
    "        Usage: judges_word_count_split(text)\n",
    "2. Number of times a judge interrupted petitioner or respondent attorneys: \n",
    "        Usage: total_interruptions_pet, total_interruptions_ret = get_total_interruptions(text)\n",
    "3. Sentiment analysis on words judges uttered to petitioner's and respondent's sides: \n",
    "        Usage: judges_speech_split(text) and sentiment analysis using existing dictionary of positive/negative\n",
    "        words\n",
    "\n",
    "We will look at each of these features one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1: Number of words judges directed at each side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can see from this illustrative example that the total number of words corresponds to roughly the sum of words\n",
    "# each judge said to each side. There might have been words uttered to speakers neither on petitioner or respondent's\n",
    "# side, or a prologue directed to the general audience (especially for the Chief Justice), which can be ignored for\n",
    "# our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSplitArgument(text):\n",
    "    '''\n",
    "    Gets split argument by RE generated with list of all speakers.\n",
    "    '''\n",
    "    # first get the names of the judges and speakers\n",
    "    pet_speakers, res_speakers, other_speakers = get_petitioners_and_respondents(text)\n",
    "    justice_speakers = getJusticeNames(clean_argument)\n",
    "    \n",
    "    # creates duplicate \"JUSTICE\" and \"CHIEF JUSTICE\"; creates RE for pet/res/justices\n",
    "    justice_RE = generateRES(justice_speakers, False)\n",
    "    pet_RE = generateRES(pet_speakers, True)\n",
    "    res_RE = generateRES(res_speakers, True)\n",
    "    \n",
    "    # appends colons to all REs\n",
    "    justice_speakers_with_colon = map(lambda name : name + \":\", justice_RE)\n",
    "    pet_speakers_with_colon = map(lambda name : name + \":\", pet_RE)\n",
    "    res_speakers_with_colon = map(lambda name : name + \":\", res_RE)\n",
    "    \n",
    "    # aggregates justice and attorney REs\n",
    "    all_speakers = [\"QUESTION\"]\n",
    "    all_speakers += (justice_RE + pet_RE + res_RE)\n",
    "    all_speakers_with_colon = map(lambda name : name + \":\", all_speakers)\n",
    "    \n",
    "    # finally, creates regular expression for the justices and attorneys (i.e. all_speakers) to split text on\n",
    "    RE = '('  + '|'.join(all_speakers_with_colon) + ')'\n",
    "    \n",
    "    # splits argument portion according to generated regular expression above that consists of all possible speakers,\n",
    "    # plebes and judges alike\n",
    "    split_argument = re.split(RE, clean_argument)\n",
    "    \n",
    "    return split_argument, all_speakers_with_colon, pet_speakers_with_colon, res_speakers_with_colon, justice_speakers_with_colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def speakersWordCount(text):\n",
    "    '''\n",
    "    FINAL FEATURE # 1:\n",
    "        Total number of words spoken by each justice in the entire transcript.\n",
    "    Output:\n",
    "        num_words: a dictionary with key being name of justice/attorney and value being total number of words they\n",
    "        spoke in total throughout argument.  \n",
    "    '''\n",
    "    splitArgument, all_speakers_with_colon, pet_speakers_with_colon, res_speakers_with_colon, _ = getSplitArgument(text)\n",
    "    \n",
    "    #num_words is a dictionary that maps all speaker names to number of words they spoke\n",
    "    currentSpeaker = 'NA:'\n",
    "    num_words = dict(zip(all_speakers_with_colon + [currentSpeaker], [0] * (len(all_speakers_with_colon)+1)))\n",
    "    \n",
    "    #iterate through split argument, accumulating word counts for all speakers\n",
    "    for s in split_argument:\n",
    "        #if split chunk signifies change in speaker\n",
    "        if s in all_speakers_with_colon:\n",
    "            currentSpeaker = s\n",
    "        #if split chunk is part of speech of current speaker, append to word count\n",
    "        else:\n",
    "            num_words[currentSpeaker] += count_words(s)\n",
    "\n",
    "    return num_words, pet_speakers_with_colon, res_speakers_with_colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deleteVal(dictionary,val):\n",
    "    '''\n",
    "    Get rid of all items in dictionary with value being a specific val: \n",
    "    E.x. when no words spoken means that we can ignore them\n",
    "    '''\n",
    "    for k,v in dictionary.items():\n",
    "        if v == val:\n",
    "            del dictionary[k]\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureOne(text):\n",
    "    numWords, pet_speakers_with_colon, res_speakers_with_colon = speakersWordCount(text)\n",
    "    numWords = deleteVal(numWords,0)\n",
    "    # clump together petitioners and respondents\n",
    "    numWordsPet, numWordsRes = 0,0\n",
    "    for s in pet_speakers_with_colon:\n",
    "        if s in numWords:\n",
    "            numWordsPet += numWords[s]\n",
    "    for s in res_speakers_with_colon:\n",
    "        if s in numWords:\n",
    "            numWordsRes += numWords[s]\n",
    "    return numWordsPet, numWordsRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3226, 2909)"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureOne(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 2: Number of interruptions per side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_num_interruptions(text):\n",
    "    '''\n",
    "    FINAL FEATURE # 2 HELPER:\n",
    "        Number of times a judge interrupted petitioner or respondent attorneys in the entire transcript.\n",
    "    Output:\n",
    "        num_interruptions: \n",
    "        a dictionary with key being name of justice/attorney speaking and value being total number of times that \n",
    "        speaker was interrupted\n",
    "    '''\n",
    "    # define the sign for an interruption at end of speech\n",
    "    interruptions = [\"-\", \"--\"]\n",
    "    \n",
    "    # get split argument\n",
    "    split_argument, all_speakers_with_colon, pet_speakers_with_colon, res_speakers_with_colon, \\\n",
    "        justice_speakers_with_colon = getSplitArgument(text)\n",
    "    \n",
    "    #num_words is a dictionary that maps all speaker names to number of words they spoke\n",
    "    current_speaker = 'NA:'\n",
    "    num_interruptions = dict(zip(all_speakers_with_colon + [current_speaker], [0] * (len(all_speakers_with_colon)+1)))\n",
    "    \n",
    "    #iterate through split argument, accumulating word counts for all speakers\n",
    "    for s in split_argument:\n",
    "        #if split chunk signifies change in speaker to a justice speaking!\n",
    "        if s in all_speakers_with_colon:\n",
    "            current_speaker = s\n",
    "        #if split chunk is part of speech of current speaker, append to word count\n",
    "        else:\n",
    "            #if speech contains at least 2 words, check whether the last or second-last contians an interruption\n",
    "            #the interruption could come as the 2nd last word when the last word is part of the first name of\n",
    "            #next speaker\n",
    "            if len(s.split()) >= 2:\n",
    "                if s.split()[-1] in interruptions or s.split()[-2] in interruptions:\n",
    "                    num_interruptions[current_speaker] += 1\n",
    "    \n",
    "    return num_interruptions, pet_speakers_with_colon, res_speakers_with_colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_interruptions, pet_speakers_with_colon, res_speakers_with_colon = get_num_interruptions(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FINAL FEATURE #2 FUNCTION\n",
    "def get_total_interruptions(text):\n",
    "    num_interruptions, pet_speakers_with_colon, res_speakers_with_colon = get_num_interruptions(text)\n",
    "    # now we need to clump petitioner and respondent interruptions together\n",
    "    total_interruptions_pet = sum([num_interruptions[k] for k in pet_speakers_with_colon])\n",
    "    total_interruptions_res = sum([num_interruptions[k] for k in res_speakers_with_colon])\n",
    "    return total_interruptions_pet, total_interruptions_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_total_interruptions(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 3: Sentiment analysis on judge's speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def judges_speech_split(text):\n",
    "    '''\n",
    "    FINAL FEATURE # 3:\n",
    "        All words said by each justice to petitioners and respondents in the entire transcript.\n",
    "    Output:\n",
    "        num_words: a dictionary with key being name of justice/attorney and value being total number of words they\n",
    "        spoke in total throughout argument.  \n",
    "    '''\n",
    "    # first get the names of the judges and speakers\n",
    "    pet_speakers, res_speakers, other_speakers = get_petitioners_and_respondents(text)\n",
    "    justice_speakers = getJusticeNames(clean_argument)\n",
    "    \n",
    "    # creates duplicate \"JUSTICE\" and \"CHIEF JUSTICE\"; creates RE for pet/res/justices\n",
    "    justice_RE = generateRES(justice_speakers, False)\n",
    "    pet_RE = generateRES(pet_speakers, True)\n",
    "    res_RE = generateRES(res_speakers, True)\n",
    "    \n",
    "    # appends colons to all REs\n",
    "    justice_speakers_with_colon = map(lambda name : name + \":\", justice_RE)\n",
    "    pet_speakers_with_colon = map(lambda name : name + \":\", pet_RE)\n",
    "    res_speakers_with_colon = map(lambda name : name + \":\", res_RE)\n",
    "    \n",
    "    # aggregates justice and attorney REs\n",
    "    all_speakers = [\"QUESTION\"]\n",
    "    all_speakers += (justice_RE + pet_RE + res_RE)\n",
    "    all_speakers_with_colon = map(lambda name : name + \":\", all_speakers)\n",
    "    \n",
    "    # finally, creates regular expression for the justices and attorneys (i.e. all_speakers) to split text on\n",
    "    RE = '('  + '|'.join(all_speakers_with_colon) + ')'\n",
    "    \n",
    "    # splits argument portion according to generated regular expression above that consists of all possible speakers,\n",
    "    # plebes and judges alike\n",
    "    split_argument = re.split(RE, clean_argument)\n",
    "    \n",
    "    #num_words is a dictionary that maps all speaker names to number of words they spoke\n",
    "    previous_speaker = 'NA:'\n",
    "    current_speaker = 'NA:'\n",
    "    words_to_pet = dict(zip(all_speakers_with_colon + [current_speaker], [\"\"] * (len(all_speakers_with_colon)+1)))\n",
    "    words_to_res = dict(zip(all_speakers_with_colon + [current_speaker], [\"\"] * (len(all_speakers_with_colon)+1)))\n",
    "    \n",
    "    #iterate through split argument, accumulating word counts for all speakers\n",
    "    for s in split_argument:\n",
    "        #if split chunk signifies change in speaker to a justice speaking!\n",
    "        if s in all_speakers_with_colon:\n",
    "            previous_speaker = current_speaker\n",
    "            current_speaker = s\n",
    "        #if split chunk is part of speech of current speaker, append to word count\n",
    "        else:\n",
    "            if current_speaker in justice_speakers_with_colon and previous_speaker in pet_speakers_with_colon:\n",
    "                words_to_pet[current_speaker] += s\n",
    "            elif current_speaker in justice_speakers_with_colon and previous_speaker in res_speakers_with_colon:\n",
    "                words_to_res[current_speaker] += s\n",
    "    \n",
    "    return words_to_pet, words_to_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_pet, words_to_res = judges_speech_split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_speeches(dictionary):\n",
    "    #joins strings that are values of a particular dictionary (want to use on words_to_pet, words_to_res)\n",
    "    return \" \".join(dictionary.values()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureThree(text):\n",
    "    #we obtain dictionaries keyed by justice with values equivalent to the stitched together speeches of every time\n",
    "    # that justice spoke up in the court proceedings\n",
    "    words_to_pet,  words_to_res = judges_speech_split(text)\n",
    "    words_to_pet = deleteVal(words_to_pet, \"\")\n",
    "    words_to_res = deleteVal(words_to_res, \"\")\n",
    "    words_to_pet = combine_speeches(words_to_pet)\n",
    "    words_to_res = combine_speeches(words_to_res)\n",
    "    petSAscore = sentimentAnalysis(words_to_pet)\n",
    "    resSAscore = sentimentAnalysis(words_to_res)\n",
    "    return petSAscore, resSAscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_pet, words_to_res = featureThree(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adapted from hw5\n",
    "def get_parts(thetext):\n",
    "    nouns=[]\n",
    "    descriptives=[]\n",
    "    for i,sentence in enumerate(parse(thetext, tokenize=True, lemmata=True).split()):\n",
    "        nouns.append([])\n",
    "        descriptives.append([])\n",
    "        for token in sentence:\n",
    "            #print token\n",
    "            if len(token[4]) >0:\n",
    "                if token[1] in ['JJ', 'JJR', 'JJS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    descriptives[i].append(token[4])\n",
    "                elif token[1] in ['NN', 'NNS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    nouns[i].append(token[4])\n",
    "    out=zip(nouns, descriptives)\n",
    "    nouns2=[]\n",
    "    descriptives2=[]\n",
    "    for n,d in out:\n",
    "        if len(n)!=0 and len(d)!=0:\n",
    "            nouns2.append(n)\n",
    "            descriptives2.append(d)\n",
    "    return nouns2, descriptives2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## TODO: change to pet speeches, and ret speeches\n",
    "parsed=[get_parts(t) for t in merged.full_text.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taking all the descriptives from the transcript. \n",
    "nbdata=[each[1] for each in parsed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#right now the list is flattened and duplicates are dropped for simplicity; room for improvement to consider dup.\n",
    "flattened=[]\n",
    "for sub_nb in nbdata:\n",
    "    flattened.append([item for l in sub_nb for item in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding the flattened list of descriptives to the dataframe as a column. \n",
    "merged['descriptives']=pd.Series(flattened, index=merged.index)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load opinion lexicon\n",
    "pos_link = \"opinion-lexicon-English/positive-words.txt\"\n",
    "neg_link = \"opinion-lexicon-English/negative-words.txt\"\n",
    "\n",
    "def get_both_list(pos_link, neg_link):\n",
    "    '''\n",
    "    This function takes the links in for the lexicon files downloaded from \n",
    "    https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "    and outputs two lists: posList and negList\n",
    "    '''\n",
    "    pos_file = open(pos_link, \"r\")\n",
    "    neg_file = open(neg_link, \"r\")\n",
    "\n",
    "    posList = pos_file.read()\n",
    "    negList = neg_file.read()\n",
    "    \n",
    "    posList=get_pos_lexicon(posList)\n",
    "    negList=get_neg_lexicon(negList)\n",
    "\n",
    "    posList=posList.split('\\n')\n",
    "    negList=negList.split('\\n')\n",
    "\n",
    "    return posList, negList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_neg_lexicon(text):\n",
    "    '''\n",
    "    This function gets neg words from the list\n",
    "    '''\n",
    "    #start and end defines bounds of argument portion of text\n",
    "    start = text.find('2-faced')\n",
    "    end = text.rfind('zombie')\n",
    "    return text[start:end]\n",
    "\n",
    "def get_pos_lexicon(text):\n",
    "    '''\n",
    "    This function gets pos words from the list.\n",
    "    '''\n",
    "    #start and end defines bounds of argument portion of text\n",
    "    start = text.find('a+')\n",
    "    end = text.rfind('zippy')\n",
    "    return text[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get posList and negList for the next step\n",
    "posList, negList = get_both_list(pos_link, neg_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_pos_neg(descriptives, posList, negList):\n",
    "    '''\n",
    "    This function takes all the descriptives for each transcript and \n",
    "    splits the list into two lists: one of positive and one of negative words. \n",
    "    '''\n",
    "    pos=[]\n",
    "    neg=[]\n",
    "    for l in descriptives:\n",
    "        positive=[]\n",
    "        negative=[]\n",
    "        for e in l:\n",
    "            if e in posList:\n",
    "                positive.append(e)\n",
    "            elif e in negList:\n",
    "                negative.append(e)\n",
    "        pos.append([positive, 'pos'])\n",
    "        neg.append([negative, 'neg'])\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos, neg=split_pos_neg(list(merged.descriptives.values), posList, negList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding the split lists to merged as columns\n",
    "merged['pos']=pd.Series(pos, index=merged.index)\n",
    "merged['neg']=pd.Series(neg, index=merged.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get net count of positive words over negative words\n",
    "net_count=[len(e1[0])-len(e2[0]) for (e1, e2) in zip(merged.pos, merged.neg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#append net_post to merged as a column\n",
    "merged['net_pos']=pd.Series(net_count, index=merged.index)\n",
    "merged.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a natural first choice for a model since our target value can be viewed as a probability between 0 or 1 for any individual justice to vote For or Against, with a higher probability representing a higher confidence of that justice voting in favor of the arguing party. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "caseId  \n",
    "docketId   \n",
    "caseIssuesId  \n",
    "voteId  \n",
    "dateDecision  \n",
    "decisionType  \n",
    "usCite  \n",
    "sctCite  \n",
    "ledCite  \n",
    "lexisCite  \n",
    "term   \n",
    "naturalCourt  \n",
    "chief  \n",
    "docket   \n",
    "caseName  \n",
    "dateArgument  \n",
    "dateRearg  \n",
    "petitioner   \n",
    "petitionerState  \n",
    "respondent  \n",
    "respondentState  \n",
    "jurisdiction  \n",
    "adminAction  \n",
    "adminActionState  \n",
    "threeJudgeFdc  \n",
    "caseOrigin  \n",
    "caseOriginState  \n",
    "caseSource  \n",
    "caseSourceState  \n",
    "lcDisagreement  \n",
    "certReason  \n",
    "lcDisposition  \n",
    "lcDispositionDirection  \n",
    "declarationUncon  \n",
    "caseDisposition   \n",
    "caseDispositionUnusual  \n",
    "partyWinning    \n",
    "precedentAlteration  \n",
    "voteUnclear    \n",
    "issue  \n",
    "issueArea  \n",
    "decisionDirection  \n",
    "decisionDirectionDissent  \n",
    "authorityDecision1  \n",
    "authorityDecision2  \n",
    "lawType  \n",
    "lawSupp  \n",
    "lawMinor  \n",
    "majOpinWriter  \n",
    "majOpinAssigner  \n",
    "splitVote  \n",
    "majVotes  \n",
    "minVotes \n",
    "\n",
    "issue: This variable identifies the issue for each decision. Although criteria for the identification of issues are hard to articulate, the focus here is on the subject matter of the controversy (e.g., sex discrimination, state tax, affirmative action) rather than its legal basis (e.g., the equal protection clause) \n",
    "\n",
    "issueArea: This variable simply separates the issues identified in the preceding variable (issue) into the following larger categories: criminal procedure (issues 10010-10600), civil rights (issues 20010-20410), First Amendment (issues 30010-30020), etc \n",
    "\n",
    "decisionDirection: In order to determine whether the Court supports or opposes the issue to which the case pertains, this variable codes the ideological \"direction\" of the decision. \n",
    "    An outcome is liberal (=2) or conservative (=1)\n",
    "\n",
    "dateDecision: This variable contains the year, month, and day that the Court announced its decision in the case.\n",
    "\n",
    "justiceName: This is a string variable indicating the first initial for the five justices with a common surname (Harlan, Johnson, Marshall, Roberts, and White) and last name of each justice.\n",
    "\n",
    "chief: This variable identifies the chief justice durinmg whose tenure the case was decided.\n",
    "\n",
    "caseSource: This variable identifies the court whose decision the Supreme Court reviewed. If the case originated in the same court whose decision the Supreme Court reviewed, the entry in the caseOrigin should be the same as here. This variable has no entry if the case arose under the Supreme Court's original jurisdiction. \n",
    "\n",
    "certReason: This variable provides the reason, if any, that the Court gives for granting the petition for certiorari. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigdf=pd.read_csv(\"SCDB_2015_01_justiceCentered_Citation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        8\n",
       "1        8\n",
       "2        8\n",
       "3        8\n",
       "4        8\n",
       "5        8\n",
       "6        8\n",
       "7        8\n",
       "8        8\n",
       "9        1\n",
       "10       1\n",
       "11       1\n",
       "12       1\n",
       "13       1\n",
       "14       1\n",
       "15       1\n",
       "16       1\n",
       "17       1\n",
       "18       8\n",
       "19       8\n",
       "20       8\n",
       "21       8\n",
       "22       8\n",
       "23       8\n",
       "24       8\n",
       "25       8\n",
       "26       8\n",
       "27       2\n",
       "28       2\n",
       "29       2\n",
       "        ..\n",
       "77312    9\n",
       "77313    9\n",
       "77314    9\n",
       "77315    2\n",
       "77316    2\n",
       "77317    2\n",
       "77318    2\n",
       "77319    2\n",
       "77320    2\n",
       "77321    2\n",
       "77322    2\n",
       "77323    2\n",
       "77324    1\n",
       "77325    1\n",
       "77326    1\n",
       "77327    1\n",
       "77328    1\n",
       "77329    1\n",
       "77330    1\n",
       "77331    1\n",
       "77332    1\n",
       "77333    2\n",
       "77334    2\n",
       "77335    2\n",
       "77336    2\n",
       "77337    2\n",
       "77338    2\n",
       "77339    2\n",
       "77340    2\n",
       "77341    2\n",
       "Name: issueArea, dtype: float64"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf['issueArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61833, 434)\n",
      "(61833, 8)\n",
      "       C(vote)[1.0]  C(vote)[2.0]  C(vote)[3.0]  C(vote)[4.0]  C(vote)[5.0]  \\\n",
      "0                 0             1             0             0             0   \n",
      "1                 1             0             0             0             0   \n",
      "2                 1             0             0             0             0   \n",
      "3                 0             0             0             1             0   \n",
      "4                 1             0             0             0             0   \n",
      "5                 1             0             0             0             0   \n",
      "6                 1             0             0             0             0   \n",
      "7                 1             0             0             0             0   \n",
      "8                 1             0             0             0             0   \n",
      "9                 1             0             0             0             0   \n",
      "10                0             1             0             0             0   \n",
      "11                1             0             0             0             0   \n",
      "12                1             0             0             0             0   \n",
      "13                1             0             0             0             0   \n",
      "14                0             1             0             0             0   \n",
      "15                0             0             0             1             0   \n",
      "16                0             1             0             0             0   \n",
      "17                1             0             0             0             0   \n",
      "18                0             1             0             0             0   \n",
      "19                1             0             0             0             0   \n",
      "20                0             1             0             0             0   \n",
      "21                0             1             0             0             0   \n",
      "22                0             1             0             0             0   \n",
      "23                1             0             0             0             0   \n",
      "24                1             0             0             0             0   \n",
      "25                1             0             0             0             0   \n",
      "26                1             0             0             0             0   \n",
      "27                0             1             0             0             0   \n",
      "29                1             0             0             0             0   \n",
      "30                1             0             0             0             0   \n",
      "...             ...           ...           ...           ...           ...   \n",
      "77312             1             0             0             0             0   \n",
      "77313             1             0             0             0             0   \n",
      "77314             1             0             0             0             0   \n",
      "77315             1             0             0             0             0   \n",
      "77316             1             0             0             0             0   \n",
      "77317             1             0             0             0             0   \n",
      "77318             1             0             0             0             0   \n",
      "77319             1             0             0             0             0   \n",
      "77320             1             0             0             0             0   \n",
      "77321             1             0             0             0             0   \n",
      "77322             1             0             0             0             0   \n",
      "77323             1             0             0             0             0   \n",
      "77324             1             0             0             0             0   \n",
      "77325             1             0             0             0             0   \n",
      "77326             1             0             0             0             0   \n",
      "77327             1             0             0             0             0   \n",
      "77328             1             0             0             0             0   \n",
      "77329             1             0             0             0             0   \n",
      "77330             1             0             0             0             0   \n",
      "77331             1             0             0             0             0   \n",
      "77332             1             0             0             0             0   \n",
      "77333             1             0             0             0             0   \n",
      "77334             1             0             0             0             0   \n",
      "77335             1             0             0             0             0   \n",
      "77336             1             0             0             0             0   \n",
      "77337             1             0             0             0             0   \n",
      "77338             1             0             0             0             0   \n",
      "77339             1             0             0             0             0   \n",
      "77340             1             0             0             0             0   \n",
      "77341             1             0             0             0             0   \n",
      "\n",
      "       C(vote)[6.0]  C(vote)[7.0]  C(vote)[8.0]  \n",
      "0                 0             0             0  \n",
      "1                 0             0             0  \n",
      "2                 0             0             0  \n",
      "3                 0             0             0  \n",
      "4                 0             0             0  \n",
      "5                 0             0             0  \n",
      "6                 0             0             0  \n",
      "7                 0             0             0  \n",
      "8                 0             0             0  \n",
      "9                 0             0             0  \n",
      "10                0             0             0  \n",
      "11                0             0             0  \n",
      "12                0             0             0  \n",
      "13                0             0             0  \n",
      "14                0             0             0  \n",
      "15                0             0             0  \n",
      "16                0             0             0  \n",
      "17                0             0             0  \n",
      "18                0             0             0  \n",
      "19                0             0             0  \n",
      "20                0             0             0  \n",
      "21                0             0             0  \n",
      "22                0             0             0  \n",
      "23                0             0             0  \n",
      "24                0             0             0  \n",
      "25                0             0             0  \n",
      "26                0             0             0  \n",
      "27                0             0             0  \n",
      "29                0             0             0  \n",
      "30                0             0             0  \n",
      "...             ...           ...           ...  \n",
      "77312             0             0             0  \n",
      "77313             0             0             0  \n",
      "77314             0             0             0  \n",
      "77315             0             0             0  \n",
      "77316             0             0             0  \n",
      "77317             0             0             0  \n",
      "77318             0             0             0  \n",
      "77319             0             0             0  \n",
      "77320             0             0             0  \n",
      "77321             0             0             0  \n",
      "77322             0             0             0  \n",
      "77323             0             0             0  \n",
      "77324             0             0             0  \n",
      "77325             0             0             0  \n",
      "77326             0             0             0  \n",
      "77327             0             0             0  \n",
      "77328             0             0             0  \n",
      "77329             0             0             0  \n",
      "77330             0             0             0  \n",
      "77331             0             0             0  \n",
      "77332             0             0             0  \n",
      "77333             0             0             0  \n",
      "77334             0             0             0  \n",
      "77335             0             0             0  \n",
      "77336             0             0             0  \n",
      "77337             0             0             0  \n",
      "77338             0             0             0  \n",
      "77339             0             0             0  \n",
      "77340             0             0             0  \n",
      "77341             0             0             0  \n",
      "\n",
      "[61833 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "bad input shape (61833, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d6f4e2250678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# check the accuracy on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/main/anaconda/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1015\u001b[0m                              % self.C)\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/main/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric)\u001b[0m\n\u001b[1;32m    447\u001b[0m                         dtype=None)\n\u001b[1;32m    448\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/main/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (61833, 8)"
     ]
    }
   ],
   "source": [
    "from patsy import dmatrices\n",
    "log_model = LogisticRegression(penalty='l2',C=1.0, fit_intercept=True, class_weight='auto')\n",
    "bigdf=pd.read_csv(\"SCDB_2015_01_justiceCentered_Citation.csv\")\n",
    "\n",
    "smalldf = pd.DataFrame()\n",
    "\n",
    "regress_vars = ['issue', 'issueArea', 'decisionDirection', \n",
    "                'dateDecision', 'justice', 'chief', 'caseSource', 'certReason', 'vote'] \n",
    "\n",
    "for i in regress_vars: \n",
    "    smalldf[i] = bigdf[i]\n",
    "    \n",
    "y, X = dmatrices('C(vote) ~ C(issue) + C(issueArea) + C(decisionDirection) + C(justice) + \\\n",
    "                  C(caseSource) + C(certReason)',\n",
    "                  smalldf, return_type=\"dataframe\")\n",
    "\n",
    "print (X.shape)\n",
    "print(y.shape)\n",
    "# y = np.ravel(y)\n",
    "print((y))\n",
    "model = LogisticRegression()\n",
    "\n",
    "model = model.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-586-6d65a5176fa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'issue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree \n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseId</th>\n",
       "      <th>docketId</th>\n",
       "      <th>caseIssuesId</th>\n",
       "      <th>voteId</th>\n",
       "      <th>dateDecision</th>\n",
       "      <th>decisionType</th>\n",
       "      <th>usCite</th>\n",
       "      <th>sctCite</th>\n",
       "      <th>ledCite</th>\n",
       "      <th>lexisCite</th>\n",
       "      <th>...</th>\n",
       "      <th>authorityDecision1</th>\n",
       "      <th>authorityDecision2</th>\n",
       "      <th>lawType</th>\n",
       "      <th>lawSupp</th>\n",
       "      <th>lawMinor</th>\n",
       "      <th>majOpinWriter</th>\n",
       "      <th>majOpinAssigner</th>\n",
       "      <th>splitVote</th>\n",
       "      <th>majVotes</th>\n",
       "      <th>minVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946-001</td>\n",
       "      <td>1946-001-01</td>\n",
       "      <td>1946-001-01-01</td>\n",
       "      <td>1946-001-01-01-01</td>\n",
       "      <td>11/18/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 1</td>\n",
       "      <td>67 S. Ct. 6</td>\n",
       "      <td>91 L. Ed. 3</td>\n",
       "      <td>1946 U.S. LEXIS 1724</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>35 U.S.C. � 33</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1946-002</td>\n",
       "      <td>1946-002-01</td>\n",
       "      <td>1946-002-01-01</td>\n",
       "      <td>1946-002-01-01-01</td>\n",
       "      <td>11/18/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 14</td>\n",
       "      <td>67 S. Ct. 13</td>\n",
       "      <td>91 L. Ed. 12</td>\n",
       "      <td>1946 U.S. LEXIS 1725</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>18 U.S.C. � 398</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946-003</td>\n",
       "      <td>1946-003-01</td>\n",
       "      <td>1946-003-01-01</td>\n",
       "      <td>1946-003-01-01-01</td>\n",
       "      <td>11/18/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 29</td>\n",
       "      <td>67 S. Ct. 1</td>\n",
       "      <td>91 L. Ed. 22</td>\n",
       "      <td>1946 U.S. LEXIS 3037</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946-004</td>\n",
       "      <td>1946-004-01</td>\n",
       "      <td>1946-004-01-01</td>\n",
       "      <td>1946-004-01-01-01</td>\n",
       "      <td>11/25/46</td>\n",
       "      <td>7</td>\n",
       "      <td>329 U.S. 40</td>\n",
       "      <td>67 S. Ct. 167</td>\n",
       "      <td>91 L. Ed. 29</td>\n",
       "      <td>1946 U.S. LEXIS 1696</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>49 Stat. 801</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1946-005</td>\n",
       "      <td>1946-005-01</td>\n",
       "      <td>1946-005-01-01</td>\n",
       "      <td>1946-005-01-01-01</td>\n",
       "      <td>11/25/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 64</td>\n",
       "      <td>67 S. Ct. 154</td>\n",
       "      <td>91 L. Ed. 44</td>\n",
       "      <td>1946 U.S. LEXIS 2997</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1946-006</td>\n",
       "      <td>1946-006-01</td>\n",
       "      <td>1946-006-01-01</td>\n",
       "      <td>1946-006-01-01-01</td>\n",
       "      <td>11/25/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 69</td>\n",
       "      <td>67 S. Ct. 156</td>\n",
       "      <td>91 L. Ed. 80</td>\n",
       "      <td>1946 U.S. LEXIS 3005</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1946-007</td>\n",
       "      <td>1946-007-01</td>\n",
       "      <td>1946-007-01-01</td>\n",
       "      <td>1946-007-01-01-01</td>\n",
       "      <td>11/25/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 90</td>\n",
       "      <td>67 S. Ct. 133</td>\n",
       "      <td>91 L. Ed. 103</td>\n",
       "      <td>1946 U.S. LEXIS 3053</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>15 U.S.C. � 79</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1946-008</td>\n",
       "      <td>1946-008-01</td>\n",
       "      <td>1946-008-01-01</td>\n",
       "      <td>1946-008-01-01-01</td>\n",
       "      <td>12/9/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 129</td>\n",
       "      <td>67 S. Ct. 231</td>\n",
       "      <td>91 L. Ed. 128</td>\n",
       "      <td>1946 U.S. LEXIS 2995</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>35 U.S.C. � 89</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1946-009</td>\n",
       "      <td>1946-009-01</td>\n",
       "      <td>1946-009-01-01</td>\n",
       "      <td>1946-009-01-01-01</td>\n",
       "      <td>12/9/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 143</td>\n",
       "      <td>67 S. Ct. 245</td>\n",
       "      <td>91 L. Ed. 136</td>\n",
       "      <td>1946 U.S. LEXIS 3047</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1946-010</td>\n",
       "      <td>1946-010-01</td>\n",
       "      <td>1946-010-01-01</td>\n",
       "      <td>1946-010-01-01-01</td>\n",
       "      <td>12/9/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 156</td>\n",
       "      <td>67 S. Ct. 237</td>\n",
       "      <td>91 L. Ed. 162</td>\n",
       "      <td>1946 U.S. LEXIS 3048</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1946-011</td>\n",
       "      <td>1946-011-01</td>\n",
       "      <td>1946-011-01-01</td>\n",
       "      <td>1946-011-01-01-01</td>\n",
       "      <td>12/9/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 173</td>\n",
       "      <td>67 S. Ct. 216</td>\n",
       "      <td>91 L. Ed. 172</td>\n",
       "      <td>1946 U.S. LEXIS 1657</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1946-012</td>\n",
       "      <td>1946-012-01</td>\n",
       "      <td>1946-012-01-01</td>\n",
       "      <td>1946-012-01-01-01</td>\n",
       "      <td>12/9/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 187</td>\n",
       "      <td>67 S. Ct. 261</td>\n",
       "      <td>91 L. Ed. 181</td>\n",
       "      <td>1946 U.S. LEXIS 1658</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1946-013</td>\n",
       "      <td>1946-013-01</td>\n",
       "      <td>1946-013-01-01</td>\n",
       "      <td>1946-013-01-01-01</td>\n",
       "      <td>12/9/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 207</td>\n",
       "      <td>67 S. Ct. 211</td>\n",
       "      <td>91 L. Ed. 193</td>\n",
       "      <td>1946 U.S. LEXIS 1659</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>50 U.S.C. � 925</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1946-014</td>\n",
       "      <td>1946-014-01</td>\n",
       "      <td>1946-014-01-01</td>\n",
       "      <td>1946-014-01-01-01</td>\n",
       "      <td>12/9/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 211</td>\n",
       "      <td>67 S. Ct. 224</td>\n",
       "      <td>91 L. Ed. 196</td>\n",
       "      <td>1946 U.S. LEXIS 1660</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>18 U.S.C. � 88</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1946-015</td>\n",
       "      <td>1946-015-01</td>\n",
       "      <td>1946-015-01-01</td>\n",
       "      <td>1946-015-01-01-01</td>\n",
       "      <td>12/9/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 223</td>\n",
       "      <td>67 S. Ct. 213</td>\n",
       "      <td>91 L. Ed. 204</td>\n",
       "      <td>1946 U.S. LEXIS 3147</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1946-016</td>\n",
       "      <td>1946-016-01</td>\n",
       "      <td>1946-016-01-01</td>\n",
       "      <td>1946-016-01-01-01</td>\n",
       "      <td>12/9/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 230</td>\n",
       "      <td>67 S. Ct. 252</td>\n",
       "      <td>91 L. Ed. 209</td>\n",
       "      <td>1946 U.S. LEXIS 2996</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>40 U.S.C. � 341</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1946-017</td>\n",
       "      <td>1946-017-01</td>\n",
       "      <td>1946-017-01-01</td>\n",
       "      <td>1946-017-01-01-01</td>\n",
       "      <td>12/16/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 249</td>\n",
       "      <td>67 S. Ct. 274</td>\n",
       "      <td>91 L. Ed. 265</td>\n",
       "      <td>1946 U.S. LEXIS 1616</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1946-018</td>\n",
       "      <td>1946-018-01</td>\n",
       "      <td>1946-018-01-01</td>\n",
       "      <td>1946-018-01-01-01</td>\n",
       "      <td>12/16/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 287</td>\n",
       "      <td>67 S. Ct. 207</td>\n",
       "      <td>91 L. Ed. 290</td>\n",
       "      <td>1946 U.S. LEXIS 1617</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>7 U.S.C. � 601</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1946-019</td>\n",
       "      <td>1946-019-01</td>\n",
       "      <td>1946-019-01-01</td>\n",
       "      <td>1946-019-01-01-01</td>\n",
       "      <td>12/16/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 296</td>\n",
       "      <td>67 S. Ct. 271</td>\n",
       "      <td>91 L. Ed. 296</td>\n",
       "      <td>1946 U.S. LEXIS 3145</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1946-020</td>\n",
       "      <td>1946-020-01</td>\n",
       "      <td>1946-020-01-01</td>\n",
       "      <td>1946-020-01-01-01</td>\n",
       "      <td>12/23/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 304</td>\n",
       "      <td>67 S. Ct. 313</td>\n",
       "      <td>91 L. Ed. 308</td>\n",
       "      <td>1946 U.S. LEXIS 1582</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1946-021</td>\n",
       "      <td>1946-021-01</td>\n",
       "      <td>1946-021-01-01</td>\n",
       "      <td>1946-021-01-01-01</td>\n",
       "      <td>12/23/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 317</td>\n",
       "      <td>67 S. Ct. 320</td>\n",
       "      <td>91 L. Ed. 318</td>\n",
       "      <td>1946 U.S. LEXIS 1583</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1946-022</td>\n",
       "      <td>1946-022-01</td>\n",
       "      <td>1946-022-01-01</td>\n",
       "      <td>1946-022-01-01-01</td>\n",
       "      <td>12/23/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 324</td>\n",
       "      <td>67 S. Ct. 324</td>\n",
       "      <td>91 L. Ed. 322</td>\n",
       "      <td>1946 U.S. LEXIS 3044</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1946-023</td>\n",
       "      <td>1946-023-01</td>\n",
       "      <td>1946-023-01-01</td>\n",
       "      <td>1946-023-01-01-01</td>\n",
       "      <td>12/23/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 338</td>\n",
       "      <td>67 S. Ct. 301</td>\n",
       "      <td>91 L. Ed. 331</td>\n",
       "      <td>1946 U.S. LEXIS 1584</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1946-024</td>\n",
       "      <td>1946-024-01</td>\n",
       "      <td>1946-024-01-01</td>\n",
       "      <td>1946-024-01-01-01</td>\n",
       "      <td>12/23/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 362</td>\n",
       "      <td>67 S. Ct. 340</td>\n",
       "      <td>91 L. Ed. 348</td>\n",
       "      <td>1946 U.S. LEXIS 3045</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1946-025</td>\n",
       "      <td>1946-025-01</td>\n",
       "      <td>1946-025-01-01</td>\n",
       "      <td>1946-025-01-01-01</td>\n",
       "      <td>12/23/46</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 379</td>\n",
       "      <td>67 S. Ct. 332</td>\n",
       "      <td>91 L. Ed. 359</td>\n",
       "      <td>1946 U.S. LEXIS 1585</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>18 U.S.C. � 413</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1946-026</td>\n",
       "      <td>1946-026-01</td>\n",
       "      <td>1946-026-01-01</td>\n",
       "      <td>1946-026-01-01-01</td>\n",
       "      <td>1/6/47</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 394</td>\n",
       "      <td>67 S. Ct. 416</td>\n",
       "      <td>91 L. Ed. 374</td>\n",
       "      <td>1947 U.S. LEXIS 3019</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1946-027</td>\n",
       "      <td>1946-027-01</td>\n",
       "      <td>1946-027-01-01</td>\n",
       "      <td>1946-027-01-01-01</td>\n",
       "      <td>1/6/47</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 402</td>\n",
       "      <td>67 S. Ct. 421</td>\n",
       "      <td>91 L. Ed. 380</td>\n",
       "      <td>1947 U.S. LEXIS 3020</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1946-028</td>\n",
       "      <td>1946-028-01</td>\n",
       "      <td>1946-028-01-01</td>\n",
       "      <td>1946-028-01-01-01</td>\n",
       "      <td>1/6/47</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 416</td>\n",
       "      <td>67 S. Ct. 444</td>\n",
       "      <td>91 L. Ed. 390</td>\n",
       "      <td>1947 U.S. LEXIS 2796</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1946-029</td>\n",
       "      <td>1946-029-01</td>\n",
       "      <td>1946-029-01-01</td>\n",
       "      <td>1946-029-01-01-01</td>\n",
       "      <td>1/6/47</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 424</td>\n",
       "      <td>67 S. Ct. 435</td>\n",
       "      <td>91 L. Ed. 396</td>\n",
       "      <td>1947 U.S. LEXIS 2902</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1946-030</td>\n",
       "      <td>1946-030-01</td>\n",
       "      <td>1946-030-01-01</td>\n",
       "      <td>1946-030-01-01-01</td>\n",
       "      <td>1/6/47</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 433</td>\n",
       "      <td>67 S. Ct. 439</td>\n",
       "      <td>91 L. Ed. 402</td>\n",
       "      <td>1947 U.S. LEXIS 2797</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1946-071</td>\n",
       "      <td>1946-071-01</td>\n",
       "      <td>1946-071-01-01</td>\n",
       "      <td>1946-071-01-01-01</td>\n",
       "      <td>3/31/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 545</td>\n",
       "      <td>67 S. Ct. 883</td>\n",
       "      <td>91 L. Ed. 1088</td>\n",
       "      <td>1947 U.S. LEXIS 2944</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1946-072</td>\n",
       "      <td>1946-072-01</td>\n",
       "      <td>1946-072-01-01</td>\n",
       "      <td>1946-072-01-01-01</td>\n",
       "      <td>3/31/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 552</td>\n",
       "      <td>67 S. Ct. 910</td>\n",
       "      <td>91 L. Ed. 1093</td>\n",
       "      <td>1947 U.S. LEXIS 2870</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1946-073</td>\n",
       "      <td>1946-073-01</td>\n",
       "      <td>1946-073-01-01</td>\n",
       "      <td>1946-073-01-01-01</td>\n",
       "      <td>3/31/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 567</td>\n",
       "      <td>67 S. Ct. 894</td>\n",
       "      <td>91 L. Ed. 1102</td>\n",
       "      <td>1947 U.S. LEXIS 2871</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1946-074</td>\n",
       "      <td>1946-074-01</td>\n",
       "      <td>1946-074-01-01</td>\n",
       "      <td>1946-074-01-01-01</td>\n",
       "      <td>3/31/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 585</td>\n",
       "      <td>67 S. Ct. 918</td>\n",
       "      <td>91 L. Ed. 1117</td>\n",
       "      <td>1947 U.S. LEXIS 2471</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>28 U.S.C. � 385</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1946-075</td>\n",
       "      <td>1946-075-01</td>\n",
       "      <td>1946-075-01-01</td>\n",
       "      <td>1946-075-01-01-01</td>\n",
       "      <td>3/31/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 610</td>\n",
       "      <td>67 S. Ct. 903</td>\n",
       "      <td>91 L. Ed. 1133</td>\n",
       "      <td>1947 U.S. LEXIS 2472</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1946-076</td>\n",
       "      <td>1946-076-01</td>\n",
       "      <td>1946-076-01-01</td>\n",
       "      <td>1946-076-01-01-01</td>\n",
       "      <td>3/31/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 622</td>\n",
       "      <td>67 S. Ct. 886</td>\n",
       "      <td>91 L. Ed. 1140</td>\n",
       "      <td>1947 U.S. LEXIS 2473</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1946-077</td>\n",
       "      <td>1946-077-01</td>\n",
       "      <td>1946-077-01-01</td>\n",
       "      <td>1946-077-01-01-01</td>\n",
       "      <td>3/31/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 631</td>\n",
       "      <td>67 S. Ct. 874</td>\n",
       "      <td>91 L. Ed. 1145</td>\n",
       "      <td>1947 U.S. LEXIS 2474</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1946-078</td>\n",
       "      <td>1946-078-01</td>\n",
       "      <td>1946-078-01-01</td>\n",
       "      <td>1946-078-01-01-01</td>\n",
       "      <td>3/31/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 649</td>\n",
       "      <td>67 S. Ct. 931</td>\n",
       "      <td>91 L. Ed. 1158</td>\n",
       "      <td>1947 U.S. LEXIS 2853</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1946-079</td>\n",
       "      <td>1946-079-01</td>\n",
       "      <td>1946-079-01-01</td>\n",
       "      <td>1946-079-01-01-01</td>\n",
       "      <td>3/31/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 695</td>\n",
       "      <td>67 S. Ct. 954</td>\n",
       "      <td>91 L. Ed. 1184</td>\n",
       "      <td>1947 U.S. LEXIS 2892</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1946-080</td>\n",
       "      <td>1946-080-01</td>\n",
       "      <td>1946-080-01-01</td>\n",
       "      <td>1946-080-01-01-01</td>\n",
       "      <td>4/7/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 709</td>\n",
       "      <td>67 S. Ct. 997</td>\n",
       "      <td>91 L. Ed. 1192</td>\n",
       "      <td>1947 U.S. LEXIS 2438</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>56 Stat. 798</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1946-081</td>\n",
       "      <td>1946-081-01</td>\n",
       "      <td>1946-081-01-01</td>\n",
       "      <td>1946-081-01-01-01</td>\n",
       "      <td>4/7/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 724</td>\n",
       "      <td>67 S. Ct. 1004</td>\n",
       "      <td>91 L. Ed. 1204</td>\n",
       "      <td>1947 U.S. LEXIS 2439</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>50 U.S.C. � 1355</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1946-082</td>\n",
       "      <td>1946-082-01</td>\n",
       "      <td>1946-082-01-01</td>\n",
       "      <td>1946-082-01-01-01</td>\n",
       "      <td>4/7/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 731</td>\n",
       "      <td>67 S. Ct. 1009</td>\n",
       "      <td>91 L. Ed. 1209</td>\n",
       "      <td>1947 U.S. LEXIS 2868</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1946-083</td>\n",
       "      <td>1946-083-01</td>\n",
       "      <td>1946-083-01-01</td>\n",
       "      <td>1946-083-01-01-01</td>\n",
       "      <td>4/7/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 743</td>\n",
       "      <td>67 S. Ct. 1015</td>\n",
       "      <td>91 L. Ed. 1219</td>\n",
       "      <td>1947 U.S. LEXIS 2440</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1946-084</td>\n",
       "      <td>1946-084-01</td>\n",
       "      <td>1946-084-01-01</td>\n",
       "      <td>1946-084-01-01-01</td>\n",
       "      <td>4/7/47</td>\n",
       "      <td>1</td>\n",
       "      <td>330 U.S. 767</td>\n",
       "      <td>67 S. Ct. 1026</td>\n",
       "      <td>91 L. Ed. 1234</td>\n",
       "      <td>1947 U.S. LEXIS 2943</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1946-085</td>\n",
       "      <td>1946-085-01</td>\n",
       "      <td>1946-085-01-01</td>\n",
       "      <td>1946-085-01-01-01</td>\n",
       "      <td>4/14/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 1</td>\n",
       "      <td>67 S. Ct. 1047</td>\n",
       "      <td>91 L. Ed. 1301</td>\n",
       "      <td>1947 U.S. LEXIS 3021</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1946-086</td>\n",
       "      <td>1946-086-01</td>\n",
       "      <td>1946-086-01-01</td>\n",
       "      <td>1946-086-01-01-01</td>\n",
       "      <td>4/14/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 17</td>\n",
       "      <td>67 S. Ct. 1056</td>\n",
       "      <td>91 L. Ed. 1312</td>\n",
       "      <td>1947 U.S. LEXIS 2941</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1946-087</td>\n",
       "      <td>1946-087-01</td>\n",
       "      <td>1946-087-01-01</td>\n",
       "      <td>1946-087-01-01-01</td>\n",
       "      <td>4/14/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 28</td>\n",
       "      <td>67 S. Ct. 1041</td>\n",
       "      <td>91 L. Ed. 1320</td>\n",
       "      <td>1947 U.S. LEXIS 2852</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1946-088</td>\n",
       "      <td>1946-088-01</td>\n",
       "      <td>1946-088-01-01</td>\n",
       "      <td>1946-088-01-01-01</td>\n",
       "      <td>4/14/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 40</td>\n",
       "      <td>67 S. Ct. 982</td>\n",
       "      <td>91 L. Ed. 1328</td>\n",
       "      <td>1947 U.S. LEXIS 2942</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1946-089</td>\n",
       "      <td>1946-089-01</td>\n",
       "      <td>1946-089-01-01</td>\n",
       "      <td>1946-089-01-01-01</td>\n",
       "      <td>4/14/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 70</td>\n",
       "      <td>67 S. Ct. 1062</td>\n",
       "      <td>91 L. Ed. 1346</td>\n",
       "      <td>1947 U.S. LEXIS 2880</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1946-090</td>\n",
       "      <td>1946-090-01</td>\n",
       "      <td>1946-090-01-01</td>\n",
       "      <td>1946-090-01-01-01</td>\n",
       "      <td>4/28/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 96</td>\n",
       "      <td>67 S. Ct. 1165</td>\n",
       "      <td>91 L. Ed. 1365</td>\n",
       "      <td>1947 U.S. LEXIS 2996</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>28 U.S.C. � 227</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1946-091</td>\n",
       "      <td>1946-091-01</td>\n",
       "      <td>1946-091-01-01</td>\n",
       "      <td>1946-091-01-01-01</td>\n",
       "      <td>4/28/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 100</td>\n",
       "      <td>67 S. Ct. 1140</td>\n",
       "      <td>91 L. Ed. 1368</td>\n",
       "      <td>1947 U.S. LEXIS 2357</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>28 U.S.C. � 401</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1946-092</td>\n",
       "      <td>1946-092-01</td>\n",
       "      <td>1946-092-01-01</td>\n",
       "      <td>1946-092-01-01-01</td>\n",
       "      <td>4/28/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 111</td>\n",
       "      <td>67 S. Ct. 1129</td>\n",
       "      <td>91 L. Ed. 1375</td>\n",
       "      <td>1947 U.S. LEXIS 2851</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1946-093</td>\n",
       "      <td>1946-093-01</td>\n",
       "      <td>1946-093-01-01</td>\n",
       "      <td>1946-093-01-01-01</td>\n",
       "      <td>4/28/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 125</td>\n",
       "      <td>67 S. Ct. 1136</td>\n",
       "      <td>91 L. Ed. 1386</td>\n",
       "      <td>1947 U.S. LEXIS 2997</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>15 U.S.C. � 99</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1946-094</td>\n",
       "      <td>1946-094-01</td>\n",
       "      <td>1946-094-01-01</td>\n",
       "      <td>1946-094-01-01-01</td>\n",
       "      <td>4/28/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 132</td>\n",
       "      <td>67 S. Ct. 1168</td>\n",
       "      <td>91 L. Ed. 1391</td>\n",
       "      <td>1947 U.S. LEXIS 2899</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>28 U.S.C. � 380</td>\n",
       "      <td>82</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1946-095</td>\n",
       "      <td>1946-095-01</td>\n",
       "      <td>1946-095-01-01</td>\n",
       "      <td>1946-095-01-01-01</td>\n",
       "      <td>5/5/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 145</td>\n",
       "      <td>67 S. Ct. 1098</td>\n",
       "      <td>91 L. Ed. 1399</td>\n",
       "      <td>1947 U.S. LEXIS 2936</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1946-096</td>\n",
       "      <td>1946-096-01</td>\n",
       "      <td>1946-096-01-01</td>\n",
       "      <td>1946-096-01-01-01</td>\n",
       "      <td>5/5/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 199</td>\n",
       "      <td>67 S. Ct. 1178</td>\n",
       "      <td>91 L. Ed. 1432</td>\n",
       "      <td>1947 U.S. LEXIS 2937</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1946-097</td>\n",
       "      <td>1946-097-01</td>\n",
       "      <td>1946-097-01-01</td>\n",
       "      <td>1946-097-01-01-01</td>\n",
       "      <td>5/5/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 210</td>\n",
       "      <td>67 S. Ct. 1175</td>\n",
       "      <td>91 L. Ed. 1441</td>\n",
       "      <td>1947 U.S. LEXIS 2994</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1946-098</td>\n",
       "      <td>1946-098-01</td>\n",
       "      <td>1946-098-01-01</td>\n",
       "      <td>1946-098-01-01-01</td>\n",
       "      <td>5/5/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 218</td>\n",
       "      <td>67 S. Ct. 1146</td>\n",
       "      <td>91 L. Ed. 1447</td>\n",
       "      <td>1947 U.S. LEXIS 2938</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>7 U.S.C. � 241</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1946-099</td>\n",
       "      <td>1946-099-01</td>\n",
       "      <td>1946-099-01-01</td>\n",
       "      <td>1946-099-01-01-01</td>\n",
       "      <td>5/5/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 247</td>\n",
       "      <td>67 S. Ct. 1160</td>\n",
       "      <td>91 L. Ed. 1468</td>\n",
       "      <td>1947 U.S. LEXIS 2319</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>7 U.S.C. � 1</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1946-100</td>\n",
       "      <td>1946-100-01</td>\n",
       "      <td>1946-100-01-01</td>\n",
       "      <td>1946-100-01-01-01</td>\n",
       "      <td>5/12/47</td>\n",
       "      <td>1</td>\n",
       "      <td>331 U.S. 256</td>\n",
       "      <td>67 S. Ct. 1287</td>\n",
       "      <td>91 L. Ed. 1474</td>\n",
       "      <td>1947 U.S. LEXIS 2867</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      caseId     docketId    caseIssuesId             voteId dateDecision  \\\n",
       "0   1946-001  1946-001-01  1946-001-01-01  1946-001-01-01-01     11/18/46   \n",
       "1   1946-002  1946-002-01  1946-002-01-01  1946-002-01-01-01     11/18/46   \n",
       "2   1946-003  1946-003-01  1946-003-01-01  1946-003-01-01-01     11/18/46   \n",
       "3   1946-004  1946-004-01  1946-004-01-01  1946-004-01-01-01     11/25/46   \n",
       "4   1946-005  1946-005-01  1946-005-01-01  1946-005-01-01-01     11/25/46   \n",
       "5   1946-006  1946-006-01  1946-006-01-01  1946-006-01-01-01     11/25/46   \n",
       "6   1946-007  1946-007-01  1946-007-01-01  1946-007-01-01-01     11/25/46   \n",
       "7   1946-008  1946-008-01  1946-008-01-01  1946-008-01-01-01      12/9/46   \n",
       "8   1946-009  1946-009-01  1946-009-01-01  1946-009-01-01-01      12/9/46   \n",
       "9   1946-010  1946-010-01  1946-010-01-01  1946-010-01-01-01      12/9/46   \n",
       "10  1946-011  1946-011-01  1946-011-01-01  1946-011-01-01-01      12/9/46   \n",
       "11  1946-012  1946-012-01  1946-012-01-01  1946-012-01-01-01      12/9/46   \n",
       "12  1946-013  1946-013-01  1946-013-01-01  1946-013-01-01-01      12/9/46   \n",
       "13  1946-014  1946-014-01  1946-014-01-01  1946-014-01-01-01      12/9/46   \n",
       "14  1946-015  1946-015-01  1946-015-01-01  1946-015-01-01-01      12/9/46   \n",
       "15  1946-016  1946-016-01  1946-016-01-01  1946-016-01-01-01      12/9/46   \n",
       "16  1946-017  1946-017-01  1946-017-01-01  1946-017-01-01-01     12/16/46   \n",
       "17  1946-018  1946-018-01  1946-018-01-01  1946-018-01-01-01     12/16/46   \n",
       "18  1946-019  1946-019-01  1946-019-01-01  1946-019-01-01-01     12/16/46   \n",
       "19  1946-020  1946-020-01  1946-020-01-01  1946-020-01-01-01     12/23/46   \n",
       "20  1946-021  1946-021-01  1946-021-01-01  1946-021-01-01-01     12/23/46   \n",
       "21  1946-022  1946-022-01  1946-022-01-01  1946-022-01-01-01     12/23/46   \n",
       "22  1946-023  1946-023-01  1946-023-01-01  1946-023-01-01-01     12/23/46   \n",
       "23  1946-024  1946-024-01  1946-024-01-01  1946-024-01-01-01     12/23/46   \n",
       "24  1946-025  1946-025-01  1946-025-01-01  1946-025-01-01-01     12/23/46   \n",
       "25  1946-026  1946-026-01  1946-026-01-01  1946-026-01-01-01       1/6/47   \n",
       "26  1946-027  1946-027-01  1946-027-01-01  1946-027-01-01-01       1/6/47   \n",
       "27  1946-028  1946-028-01  1946-028-01-01  1946-028-01-01-01       1/6/47   \n",
       "28  1946-029  1946-029-01  1946-029-01-01  1946-029-01-01-01       1/6/47   \n",
       "29  1946-030  1946-030-01  1946-030-01-01  1946-030-01-01-01       1/6/47   \n",
       "..       ...          ...             ...                ...          ...   \n",
       "70  1946-071  1946-071-01  1946-071-01-01  1946-071-01-01-01      3/31/47   \n",
       "71  1946-072  1946-072-01  1946-072-01-01  1946-072-01-01-01      3/31/47   \n",
       "72  1946-073  1946-073-01  1946-073-01-01  1946-073-01-01-01      3/31/47   \n",
       "73  1946-074  1946-074-01  1946-074-01-01  1946-074-01-01-01      3/31/47   \n",
       "74  1946-075  1946-075-01  1946-075-01-01  1946-075-01-01-01      3/31/47   \n",
       "75  1946-076  1946-076-01  1946-076-01-01  1946-076-01-01-01      3/31/47   \n",
       "76  1946-077  1946-077-01  1946-077-01-01  1946-077-01-01-01      3/31/47   \n",
       "77  1946-078  1946-078-01  1946-078-01-01  1946-078-01-01-01      3/31/47   \n",
       "78  1946-079  1946-079-01  1946-079-01-01  1946-079-01-01-01      3/31/47   \n",
       "79  1946-080  1946-080-01  1946-080-01-01  1946-080-01-01-01       4/7/47   \n",
       "80  1946-081  1946-081-01  1946-081-01-01  1946-081-01-01-01       4/7/47   \n",
       "81  1946-082  1946-082-01  1946-082-01-01  1946-082-01-01-01       4/7/47   \n",
       "82  1946-083  1946-083-01  1946-083-01-01  1946-083-01-01-01       4/7/47   \n",
       "83  1946-084  1946-084-01  1946-084-01-01  1946-084-01-01-01       4/7/47   \n",
       "84  1946-085  1946-085-01  1946-085-01-01  1946-085-01-01-01      4/14/47   \n",
       "85  1946-086  1946-086-01  1946-086-01-01  1946-086-01-01-01      4/14/47   \n",
       "86  1946-087  1946-087-01  1946-087-01-01  1946-087-01-01-01      4/14/47   \n",
       "87  1946-088  1946-088-01  1946-088-01-01  1946-088-01-01-01      4/14/47   \n",
       "88  1946-089  1946-089-01  1946-089-01-01  1946-089-01-01-01      4/14/47   \n",
       "89  1946-090  1946-090-01  1946-090-01-01  1946-090-01-01-01      4/28/47   \n",
       "90  1946-091  1946-091-01  1946-091-01-01  1946-091-01-01-01      4/28/47   \n",
       "91  1946-092  1946-092-01  1946-092-01-01  1946-092-01-01-01      4/28/47   \n",
       "92  1946-093  1946-093-01  1946-093-01-01  1946-093-01-01-01      4/28/47   \n",
       "93  1946-094  1946-094-01  1946-094-01-01  1946-094-01-01-01      4/28/47   \n",
       "94  1946-095  1946-095-01  1946-095-01-01  1946-095-01-01-01       5/5/47   \n",
       "95  1946-096  1946-096-01  1946-096-01-01  1946-096-01-01-01       5/5/47   \n",
       "96  1946-097  1946-097-01  1946-097-01-01  1946-097-01-01-01       5/5/47   \n",
       "97  1946-098  1946-098-01  1946-098-01-01  1946-098-01-01-01       5/5/47   \n",
       "98  1946-099  1946-099-01  1946-099-01-01  1946-099-01-01-01       5/5/47   \n",
       "99  1946-100  1946-100-01  1946-100-01-01  1946-100-01-01-01      5/12/47   \n",
       "\n",
       "    decisionType        usCite         sctCite         ledCite  \\\n",
       "0              1    329 U.S. 1     67 S. Ct. 6     91 L. Ed. 3   \n",
       "1              1   329 U.S. 14    67 S. Ct. 13    91 L. Ed. 12   \n",
       "2              1   329 U.S. 29     67 S. Ct. 1    91 L. Ed. 22   \n",
       "3              7   329 U.S. 40   67 S. Ct. 167    91 L. Ed. 29   \n",
       "4              1   329 U.S. 64   67 S. Ct. 154    91 L. Ed. 44   \n",
       "5              1   329 U.S. 69   67 S. Ct. 156    91 L. Ed. 80   \n",
       "6              1   329 U.S. 90   67 S. Ct. 133   91 L. Ed. 103   \n",
       "7              1  329 U.S. 129   67 S. Ct. 231   91 L. Ed. 128   \n",
       "8              1  329 U.S. 143   67 S. Ct. 245   91 L. Ed. 136   \n",
       "9              1  329 U.S. 156   67 S. Ct. 237   91 L. Ed. 162   \n",
       "10             1  329 U.S. 173   67 S. Ct. 216   91 L. Ed. 172   \n",
       "11             1  329 U.S. 187   67 S. Ct. 261   91 L. Ed. 181   \n",
       "12             1  329 U.S. 207   67 S. Ct. 211   91 L. Ed. 193   \n",
       "13             1  329 U.S. 211   67 S. Ct. 224   91 L. Ed. 196   \n",
       "14             1  329 U.S. 223   67 S. Ct. 213   91 L. Ed. 204   \n",
       "15             1  329 U.S. 230   67 S. Ct. 252   91 L. Ed. 209   \n",
       "16             1  329 U.S. 249   67 S. Ct. 274   91 L. Ed. 265   \n",
       "17             1  329 U.S. 287   67 S. Ct. 207   91 L. Ed. 290   \n",
       "18             1  329 U.S. 296   67 S. Ct. 271   91 L. Ed. 296   \n",
       "19             1  329 U.S. 304   67 S. Ct. 313   91 L. Ed. 308   \n",
       "20             1  329 U.S. 317   67 S. Ct. 320   91 L. Ed. 318   \n",
       "21             1  329 U.S. 324   67 S. Ct. 324   91 L. Ed. 322   \n",
       "22             1  329 U.S. 338   67 S. Ct. 301   91 L. Ed. 331   \n",
       "23             1  329 U.S. 362   67 S. Ct. 340   91 L. Ed. 348   \n",
       "24             1  329 U.S. 379   67 S. Ct. 332   91 L. Ed. 359   \n",
       "25             1  329 U.S. 394   67 S. Ct. 416   91 L. Ed. 374   \n",
       "26             1  329 U.S. 402   67 S. Ct. 421   91 L. Ed. 380   \n",
       "27             1  329 U.S. 416   67 S. Ct. 444   91 L. Ed. 390   \n",
       "28             1  329 U.S. 424   67 S. Ct. 435   91 L. Ed. 396   \n",
       "29             1  329 U.S. 433   67 S. Ct. 439   91 L. Ed. 402   \n",
       "..           ...           ...             ...             ...   \n",
       "70             1  330 U.S. 545   67 S. Ct. 883  91 L. Ed. 1088   \n",
       "71             1  330 U.S. 552   67 S. Ct. 910  91 L. Ed. 1093   \n",
       "72             1  330 U.S. 567   67 S. Ct. 894  91 L. Ed. 1102   \n",
       "73             1  330 U.S. 585   67 S. Ct. 918  91 L. Ed. 1117   \n",
       "74             1  330 U.S. 610   67 S. Ct. 903  91 L. Ed. 1133   \n",
       "75             1  330 U.S. 622   67 S. Ct. 886  91 L. Ed. 1140   \n",
       "76             1  330 U.S. 631   67 S. Ct. 874  91 L. Ed. 1145   \n",
       "77             1  330 U.S. 649   67 S. Ct. 931  91 L. Ed. 1158   \n",
       "78             1  330 U.S. 695   67 S. Ct. 954  91 L. Ed. 1184   \n",
       "79             1  330 U.S. 709   67 S. Ct. 997  91 L. Ed. 1192   \n",
       "80             1  330 U.S. 724  67 S. Ct. 1004  91 L. Ed. 1204   \n",
       "81             1  330 U.S. 731  67 S. Ct. 1009  91 L. Ed. 1209   \n",
       "82             1  330 U.S. 743  67 S. Ct. 1015  91 L. Ed. 1219   \n",
       "83             1  330 U.S. 767  67 S. Ct. 1026  91 L. Ed. 1234   \n",
       "84             1    331 U.S. 1  67 S. Ct. 1047  91 L. Ed. 1301   \n",
       "85             1   331 U.S. 17  67 S. Ct. 1056  91 L. Ed. 1312   \n",
       "86             1   331 U.S. 28  67 S. Ct. 1041  91 L. Ed. 1320   \n",
       "87             1   331 U.S. 40   67 S. Ct. 982  91 L. Ed. 1328   \n",
       "88             1   331 U.S. 70  67 S. Ct. 1062  91 L. Ed. 1346   \n",
       "89             1   331 U.S. 96  67 S. Ct. 1165  91 L. Ed. 1365   \n",
       "90             1  331 U.S. 100  67 S. Ct. 1140  91 L. Ed. 1368   \n",
       "91             1  331 U.S. 111  67 S. Ct. 1129  91 L. Ed. 1375   \n",
       "92             1  331 U.S. 125  67 S. Ct. 1136  91 L. Ed. 1386   \n",
       "93             1  331 U.S. 132  67 S. Ct. 1168  91 L. Ed. 1391   \n",
       "94             1  331 U.S. 145  67 S. Ct. 1098  91 L. Ed. 1399   \n",
       "95             1  331 U.S. 199  67 S. Ct. 1178  91 L. Ed. 1432   \n",
       "96             1  331 U.S. 210  67 S. Ct. 1175  91 L. Ed. 1441   \n",
       "97             1  331 U.S. 218  67 S. Ct. 1146  91 L. Ed. 1447   \n",
       "98             1  331 U.S. 247  67 S. Ct. 1160  91 L. Ed. 1468   \n",
       "99             1  331 U.S. 256  67 S. Ct. 1287  91 L. Ed. 1474   \n",
       "\n",
       "               lexisCite    ...     authorityDecision1  authorityDecision2  \\\n",
       "0   1946 U.S. LEXIS 1724    ...                      4                 NaN   \n",
       "1   1946 U.S. LEXIS 1725    ...                      4                 NaN   \n",
       "2   1946 U.S. LEXIS 3037    ...                      1                 NaN   \n",
       "3   1946 U.S. LEXIS 1696    ...                      4                 NaN   \n",
       "4   1946 U.S. LEXIS 2997    ...                      7                 NaN   \n",
       "5   1946 U.S. LEXIS 3005    ...                      2                 NaN   \n",
       "6   1946 U.S. LEXIS 3053    ...                      1                 NaN   \n",
       "7   1946 U.S. LEXIS 2995    ...                      4                 NaN   \n",
       "8   1946 U.S. LEXIS 3047    ...                      4                   5   \n",
       "9   1946 U.S. LEXIS 3048    ...                      4                 NaN   \n",
       "10  1946 U.S. LEXIS 1657    ...                      2                 NaN   \n",
       "11  1946 U.S. LEXIS 1658    ...                      3                 NaN   \n",
       "12  1946 U.S. LEXIS 1659    ...                      4                 NaN   \n",
       "13  1946 U.S. LEXIS 1660    ...                      4                 NaN   \n",
       "14  1946 U.S. LEXIS 3147    ...                      4                   5   \n",
       "15  1946 U.S. LEXIS 2996    ...                      4                 NaN   \n",
       "16  1946 U.S. LEXIS 1616    ...                      2                 NaN   \n",
       "17  1946 U.S. LEXIS 1617    ...                      5                   4   \n",
       "18  1946 U.S. LEXIS 3145    ...                      7                 NaN   \n",
       "19  1946 U.S. LEXIS 1582    ...                      5                   4   \n",
       "20  1946 U.S. LEXIS 1583    ...                      5                   4   \n",
       "21  1946 U.S. LEXIS 3044    ...                      5                   4   \n",
       "22  1946 U.S. LEXIS 1584    ...                      4                 NaN   \n",
       "23  1946 U.S. LEXIS 3045    ...                      4                 NaN   \n",
       "24  1946 U.S. LEXIS 1585    ...                      4                 NaN   \n",
       "25  1947 U.S. LEXIS 3019    ...                      7                 NaN   \n",
       "26  1947 U.S. LEXIS 3020    ...                      7                 NaN   \n",
       "27  1947 U.S. LEXIS 2796    ...                      2                 NaN   \n",
       "28  1947 U.S. LEXIS 2902    ...                      4                   5   \n",
       "29  1947 U.S. LEXIS 2797    ...                      6                 NaN   \n",
       "..                   ...    ...                    ...                 ...   \n",
       "70  1947 U.S. LEXIS 2944    ...                      4                 NaN   \n",
       "71  1947 U.S. LEXIS 2870    ...                      2                 NaN   \n",
       "72  1947 U.S. LEXIS 2871    ...                      5                   4   \n",
       "73  1947 U.S. LEXIS 2471    ...                      4                 NaN   \n",
       "74  1947 U.S. LEXIS 2472    ...                      2                 NaN   \n",
       "75  1947 U.S. LEXIS 2473    ...                      2                 NaN   \n",
       "76  1947 U.S. LEXIS 2474    ...                      1                 NaN   \n",
       "77  1947 U.S. LEXIS 2853    ...                      4                 NaN   \n",
       "78  1947 U.S. LEXIS 2892    ...                      4                 NaN   \n",
       "79  1947 U.S. LEXIS 2438    ...                      4                 NaN   \n",
       "80  1947 U.S. LEXIS 2439    ...                      4                 NaN   \n",
       "81  1947 U.S. LEXIS 2868    ...                      4                 NaN   \n",
       "82  1947 U.S. LEXIS 2440    ...                      4                 NaN   \n",
       "83  1947 U.S. LEXIS 2943    ...                      4                 NaN   \n",
       "84  1947 U.S. LEXIS 3021    ...                      4                 NaN   \n",
       "85  1947 U.S. LEXIS 2941    ...                      4                 NaN   \n",
       "86  1947 U.S. LEXIS 2852    ...                      4                 NaN   \n",
       "87  1947 U.S. LEXIS 2942    ...                      4                 NaN   \n",
       "88  1947 U.S. LEXIS 2880    ...                      2                 NaN   \n",
       "89  1947 U.S. LEXIS 2996    ...                      4                 NaN   \n",
       "90  1947 U.S. LEXIS 2357    ...                      4                 NaN   \n",
       "91  1947 U.S. LEXIS 2851    ...                      4                 NaN   \n",
       "92  1947 U.S. LEXIS 2997    ...                      4                 NaN   \n",
       "93  1947 U.S. LEXIS 2899    ...                      4                 NaN   \n",
       "94  1947 U.S. LEXIS 2936    ...                      1                 NaN   \n",
       "95  1947 U.S. LEXIS 2937    ...                      4                 NaN   \n",
       "96  1947 U.S. LEXIS 2994    ...                      4                 NaN   \n",
       "97  1947 U.S. LEXIS 2938    ...                      2                 NaN   \n",
       "98  1947 U.S. LEXIS 2319    ...                      4                 NaN   \n",
       "99  1947 U.S. LEXIS 2867    ...                      4                 NaN   \n",
       "\n",
       "   lawType lawSupp          lawMinor majOpinWriter majOpinAssigner  splitVote  \\\n",
       "0        6     600    35 U.S.C. � 33            78              78          1   \n",
       "1        6     600   18 U.S.C. � 398            81              87          1   \n",
       "2        2     207               NaN            84              78          1   \n",
       "3        6     600      49 Stat. 801            87              87          1   \n",
       "4      NaN     NaN               NaN            78              87          1   \n",
       "5        1     129               NaN            81              87          1   \n",
       "6        6     600    15 U.S.C. � 79            82              74          1   \n",
       "7        6     600    35 U.S.C. � 89            87              87          1   \n",
       "8        5     512               NaN            87              87          1   \n",
       "9        3     307               NaN            78              87          1   \n",
       "10       2     214               NaN            80              87          1   \n",
       "11     NaN     NaN               NaN            81              78          1   \n",
       "12       6     600   50 U.S.C. � 925            81              78          1   \n",
       "13       6     600    18 U.S.C. � 88            81              78          1   \n",
       "14       3     326               NaN            84              87          1   \n",
       "15       6     600   40 U.S.C. � 341            86              87          1   \n",
       "16       1     111               NaN            80              74          1   \n",
       "17       6     600    7 U.S.C. � 601            80              87          1   \n",
       "18     NaN     NaN               NaN            84              87          1   \n",
       "19       3     366               NaN            81              87          1   \n",
       "20       3     366               NaN            81              87          1   \n",
       "21       3     356               NaN            82              87          1   \n",
       "22       3     366               NaN            85              78          1   \n",
       "23       3     307               NaN            85              87          1   \n",
       "24       6     600   18 U.S.C. � 413            85              78          1   \n",
       "25       5     507               NaN            78              87          1   \n",
       "26       5     507               NaN            78              87          1   \n",
       "27       2     230               NaN            78              87          1   \n",
       "28       3     343               NaN            78              87          1   \n",
       "29     NaN     NaN               NaN            78              87          1   \n",
       "..     ...     ...               ...           ...             ...        ...   \n",
       "70       3     334               NaN            87              87          1   \n",
       "71       2     231               NaN            78              87          1   \n",
       "72       3     343               NaN            78              87          1   \n",
       "73       6     600   28 U.S.C. � 385            81              87          1   \n",
       "74       1     143               NaN            81              78          1   \n",
       "75       1     143               NaN            82              87          1   \n",
       "76       1     142               NaN            84              87          1   \n",
       "77       3     334               NaN            86              87          1   \n",
       "78       3     352               NaN            86              87          1   \n",
       "79       6     600      56 Stat. 798            78              87          1   \n",
       "80       6     600  50 U.S.C. � 1355            78              78          1   \n",
       "81       4     400               NaN            81              87          1   \n",
       "82       3     364               NaN            84              87          1   \n",
       "83       3     356               NaN            84              87          1   \n",
       "84       3     345               NaN            87              87          1   \n",
       "85       3     334               NaN            87              87          1   \n",
       "86       3     307               NaN            82              87          1   \n",
       "87       3     366               NaN            85              87          1   \n",
       "88       2     231               NaN            85              78          1   \n",
       "89       6     600   28 U.S.C. � 227            78              78          1   \n",
       "90       6     600   28 U.S.C. � 401            79              87          1   \n",
       "91       4     400               NaN            81              87          1   \n",
       "92       6     600    15 U.S.C. � 99            81              87          1   \n",
       "93       6     600   28 U.S.C. � 380            82              87          1   \n",
       "94       2     205               NaN            87              87          1   \n",
       "95       3     334               NaN            87              87          1   \n",
       "96       3     345               NaN            78              87          1   \n",
       "97       6     600    7 U.S.C. � 241            81              87          1   \n",
       "98       6     600      7 U.S.C. � 1            81              87          1   \n",
       "99       5     512               NaN            79              79          1   \n",
       "\n",
       "    majVotes  minVotes  \n",
       "0          8         1  \n",
       "1          6         3  \n",
       "2          5         4  \n",
       "3          5         3  \n",
       "4          6         3  \n",
       "5          7         1  \n",
       "6          6         0  \n",
       "7          9         0  \n",
       "8          9         0  \n",
       "9          8         0  \n",
       "10         5         4  \n",
       "11         6         3  \n",
       "12         9         0  \n",
       "13         9         0  \n",
       "14         8         0  \n",
       "15         9         0  \n",
       "16         6         3  \n",
       "17         9         0  \n",
       "18         6         3  \n",
       "19         9         0  \n",
       "20         9         0  \n",
       "21         8         1  \n",
       "22         9         0  \n",
       "23         7         2  \n",
       "24         7         2  \n",
       "25         5         4  \n",
       "26         5         4  \n",
       "27         9         0  \n",
       "28         9         0  \n",
       "29         9         0  \n",
       "..       ...       ...  \n",
       "70         6         3  \n",
       "71         5         4  \n",
       "72         7         2  \n",
       "73         7         2  \n",
       "74         9         0  \n",
       "75         9         0  \n",
       "76         8         1  \n",
       "77         6         3  \n",
       "78         9         0  \n",
       "79         7         2  \n",
       "80         9         0  \n",
       "81         8         0  \n",
       "82         5         4  \n",
       "83         9         0  \n",
       "84         6         3  \n",
       "85         7         2  \n",
       "86         8         1  \n",
       "87         7         2  \n",
       "88         7         2  \n",
       "89         9         0  \n",
       "90         8         1  \n",
       "91         9         0  \n",
       "92         9         0  \n",
       "93         8         1  \n",
       "94         5         4  \n",
       "95         9         0  \n",
       "96         9         0  \n",
       "97         7         2  \n",
       "98         9         0  \n",
       "99         5         4  \n",
       "\n",
       "[100 rows x 53 columns]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in SCDB data from file\n",
    "bigdf=pd.read_csv(\"supremeCourtDb.csv\")\n",
    "bigdf[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('docketId', 'dateDecision', 'case')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-045043c2ac69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"docketId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dateDecision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"case\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/main/anaconda/lib/python2.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1912\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/main/anaconda/lib/python2.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1919\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/main/anaconda/lib/python2.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/main/anaconda/lib/python2.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3102\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3103\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/main/anaconda/lib/python2.7/site-packages/pandas/core/index.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1690\u001b[0m                 raise ValueError('tolerance argument only valid if using pad, '\n\u001b[1;32m   1691\u001b[0m                                  'backfill or nearest lookups')\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('docketId', 'dateDecision', 'case')"
     ]
    }
   ],
   "source": [
    "df = bigdf[\"docketId\", \"dateDecision\", \"case\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(C=1.0, kernel='linear', probability=True, class_weight='auto')\n",
    "svm_model = my_svm.fit(X, y)\n",
    "svm_pred = svm_fit.predict(W)\n",
    "# Class probabilities, based on log regression on distance to hyperplane.\n",
    "svm_prob = svm_fit.predict_proba(W)\n",
    "svm_dist = svm_fit.decision_function(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Justice Ruling Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a different dataset in a slightly different approach to making Supreme Court ruling predictions. This method is motivated by the fact that usually, only 2 justices tend to be swing votes and justice decisions are highly influenced by factors outside of what transpires in court proceedings, such as background information about the case itself. The Supreme Court website contains a Justice-centered database which contains extensive information about each case; in particular, the most pertinent fields we are interested in analyzing are:\n",
    "\n",
    "1. Decision Year\n",
    "2. Natural Court\n",
    "3. Petitioner\n",
    "4. Respondent\n",
    "5. Case Origin\n",
    "6. Case Source\n",
    "7. Lower Court Disposition Direction\n",
    "8. Issue Area\n",
    "\n",
    "Our target value to predict is the field called winningParty (petitioner or respondent), which using our justice-centered approach involves aggregating predicted votes for each individual justice and taking majority vote. The associated confidence of our entire prediction is obtained by averaging individual confidences of our models for each justice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in justice-centered SCDB data from file\n",
    "newdf=pd.read_csv(\"SCDB_justice_centered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2853c809a88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# maybe lcDispositionDirection? choose features with continuous/numerical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# do the numbers mean anything though?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnewsmalldf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"term\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"naturalCourt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"petitioner\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"respondent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"caseOrigin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"caseSource\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lcDisposition\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"issueArea\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewsmalldf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'newdf' is not defined"
     ]
    }
   ],
   "source": [
    "# maybe lcDispositionDirection? choose features with continuous/numerical features\n",
    "# do the numbers mean anything though?\n",
    "newsmalldf = newdf[[\"term\", \"naturalCourt\", \"petitioner\", \"respondent\", \"caseOrigin\", \"caseSource\", \"lcDisposition\", \"issueArea\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>naturalCourt</th>\n",
       "      <th>petitioner</th>\n",
       "      <th>respondent</th>\n",
       "      <th>caseOrigin</th>\n",
       "      <th>caseSource</th>\n",
       "      <th>lcDisposition</th>\n",
       "      <th>issueArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term  naturalCourt  petitioner  respondent  caseOrigin  caseSource  \\\n",
       "0  1946          1301         198         172          51          29   \n",
       "1  1946          1301         198         172          51          29   \n",
       "2  1946          1301         198         172          51          29   \n",
       "3  1946          1301         198         172          51          29   \n",
       "4  1946          1301         198         172          51          29   \n",
       "\n",
       "   lcDisposition  issueArea  \n",
       "0              2          8  \n",
       "1              2          8  \n",
       "2              2          8  \n",
       "3              2          8  \n",
       "4              2          8  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsmalldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an intuitive understanding of the features above, check out the documentation here: http://scdb.wustl.edu/documentation.php?var=petitioner. All the above features are categorical instead of continuous (which means the numbers specify a category instead of having a numerical meaning). For an illustrative example, the \"petitioner\" variable includes:\n",
    "\n",
    "1. attorney general of the United States, or his office\n",
    "2. specified state board or department of education\n",
    "7. state department or agency\n",
    "etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages of Using Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having an intuitive understanding of the meanings behind the variables is important and leads us to our idea of usign the decision tree classifier. A distinct advantage of using decisiontrees is that the decision at each node has an intuitive meaning and corresponds to querying along one feature axis at a time (e.g. is the petitioner an attorney general of the United States?). \n",
    "\n",
    "Furthermore, trees are easy to understand and interpret. We can look at the top node and figure out which feature it corresponds to, and conclude that this feature contributes the most information gain, i.e. is the most important/predictive feature. This makes it easy to verify whether our results make intuitive sense.\n",
    "\n",
    "We will show the process of running decision trees on each justice, before aggregating the votes now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Justice-Centered Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, the feature that we want to predict is the vote for each justice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# newdf.majority refers to whether justice voted with the majority (1 for dissent, 2 for majority)\n",
    "# newdf.partyWinning indicates winning party (0 for responding party, 1 for petitioning party, 2 for unclear)\n",
    "# We use the above 2 features to infer which party the individual justice voted for\n",
    "# NOTE: majority has around 4000 NaNs that we should filter out?\n",
    "results = []\n",
    "ctr1, ctr2 = 0,0\n",
    "for idx, x in enumerate(newdf.majority):\n",
    "    #if decision is unclear, append 2 to results (in reality, apparently there aren't ANY 2s)\n",
    "    if newdf.partyWinning[idx] == 2:\n",
    "        results.append(2)\n",
    "        ctr += 1\n",
    "        break\n",
    "    #if justice voted in the majority\n",
    "    if x == 2:\n",
    "        results.append(newdf.partyWinning[idx]) #results contains 0/1\n",
    "    #if justice voted in the minority\n",
    "    elif x == 1:\n",
    "        results.append(1 - newdf.partyWinning[idx]) #results contains 0/1\n",
    "    else:\n",
    "        #need to clean this up o.o\n",
    "        results.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-36f959fc3bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# these are our target values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnewsmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/idzhang/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   4218\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4219\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 4220\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   4221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4222\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/Users/idzhang/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   4247\u001b[0m             \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4249\u001b[0;31m             \u001b[0mcan_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcan_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/idzhang/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((df,))\u001b[0m\n\u001b[1;32m   4247\u001b[0m             \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4249\u001b[0;31m             \u001b[0mcan_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcan_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "# these are our target values\n",
    "pd.concat([newsmalldf, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>naturalCourt</th>\n",
       "      <th>petitioner</th>\n",
       "      <th>respondent</th>\n",
       "      <th>caseOrigin</th>\n",
       "      <th>caseSource</th>\n",
       "      <th>lcDisposition</th>\n",
       "      <th>issueArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term  naturalCourt  petitioner  respondent  caseOrigin  caseSource  \\\n",
       "0  1946          1301         198         172          51          29   \n",
       "1  1946          1301         198         172          51          29   \n",
       "2  1946          1301         198         172          51          29   \n",
       "3  1946          1301         198         172          51          29   \n",
       "4  1946          1301         198         172          51          29   \n",
       "\n",
       "   lcDisposition  issueArea  \n",
       "0              2          8  \n",
       "1              2          8  \n",
       "2              2          8  \n",
       "3              2          8  \n",
       "4              2          8  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows where any column value is NaN - dealing with missing data\n",
    "newsmalldf.dropna(axis=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114895, 114895)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsmalldf), len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idzhang/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "newsmalldf[\"results\"] = pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>naturalCourt</th>\n",
       "      <th>petitioner</th>\n",
       "      <th>respondent</th>\n",
       "      <th>caseOrigin</th>\n",
       "      <th>caseSource</th>\n",
       "      <th>lcDisposition</th>\n",
       "      <th>issueArea</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>198</td>\n",
       "      <td>172</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114865</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>300</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114866</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>300</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114867</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>300</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114868</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>251</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114869</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>251</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114870</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>251</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114871</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>251</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114872</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>251</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114873</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>251</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114874</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>251</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114875</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>251</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114876</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>251</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114877</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114878</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114879</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114880</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114881</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114882</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114883</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114884</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114885</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114886</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>14</td>\n",
       "      <td>162</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114887</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>14</td>\n",
       "      <td>162</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114888</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>14</td>\n",
       "      <td>162</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114889</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>14</td>\n",
       "      <td>162</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114890</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>14</td>\n",
       "      <td>162</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114891</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>14</td>\n",
       "      <td>162</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114892</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>14</td>\n",
       "      <td>162</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114893</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>14</td>\n",
       "      <td>162</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114894</th>\n",
       "      <td>2012</td>\n",
       "      <td>1704</td>\n",
       "      <td>14</td>\n",
       "      <td>162</td>\n",
       "      <td>96</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114895 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        term  naturalCourt  petitioner  respondent  caseOrigin  caseSource  \\\n",
       "0       1946          1301         198         172          51          29   \n",
       "1       1946          1301         198         172          51          29   \n",
       "2       1946          1301         198         172          51          29   \n",
       "3       1946          1301         198         172          51          29   \n",
       "4       1946          1301         198         172          51          29   \n",
       "5       1946          1301         198         172          51          29   \n",
       "6       1946          1301         198         172          51          29   \n",
       "7       1946          1301         198         172          51          29   \n",
       "8       1946          1301         198         172          51          29   \n",
       "9       1946          1301         100          27         123          30   \n",
       "10      1946          1301         100          27         123          30   \n",
       "11      1946          1301         100          27         123          30   \n",
       "12      1946          1301         100          27         123          30   \n",
       "13      1946          1301         100          27         123          30   \n",
       "14      1946          1301         100          27         123          30   \n",
       "15      1946          1301         100          27         123          30   \n",
       "16      1946          1301         100          27         123          30   \n",
       "17      1946          1301         100          27         123          30   \n",
       "18      1946          1301         100          27         123          30   \n",
       "19      1946          1301         100          27         123          30   \n",
       "20      1946          1301         100          27         123          30   \n",
       "21      1946          1301         100          27         123          30   \n",
       "22      1946          1301         100          27         123          30   \n",
       "23      1946          1301         100          27         123          30   \n",
       "24      1946          1301         100          27         123          30   \n",
       "25      1946          1301         100          27         123          30   \n",
       "26      1946          1301         100          27         123          30   \n",
       "27      1946          1301         100          27         123          30   \n",
       "28      1946          1301         100          27         123          30   \n",
       "29      1946          1301         100          27         123          30   \n",
       "...      ...           ...         ...         ...         ...         ...   \n",
       "114865  2012          1704           4         126         300          29   \n",
       "114866  2012          1704           4         126         300          29   \n",
       "114867  2012          1704           4         126         300          29   \n",
       "114868  2012          1704         251         162          50          29   \n",
       "114869  2012          1704         251         162          50          29   \n",
       "114870  2012          1704         251         162          50          29   \n",
       "114871  2012          1704         251         162          50          29   \n",
       "114872  2012          1704         251         162          50          29   \n",
       "114873  2012          1704         251         162          50          29   \n",
       "114874  2012          1704         251         162          50          29   \n",
       "114875  2012          1704         251         162          50          29   \n",
       "114876  2012          1704         251         162          50          29   \n",
       "114877  2012          1704         126          27          96          22   \n",
       "114878  2012          1704         126          27          96          22   \n",
       "114879  2012          1704         126          27          96          22   \n",
       "114880  2012          1704         126          27          96          22   \n",
       "114881  2012          1704         126          27          96          22   \n",
       "114882  2012          1704         126          27          96          22   \n",
       "114883  2012          1704         126          27          96          22   \n",
       "114884  2012          1704         126          27          96          22   \n",
       "114885  2012          1704         126          27          96          22   \n",
       "114886  2012          1704          14         162          96          22   \n",
       "114887  2012          1704          14         162          96          22   \n",
       "114888  2012          1704          14         162          96          22   \n",
       "114889  2012          1704          14         162          96          22   \n",
       "114890  2012          1704          14         162          96          22   \n",
       "114891  2012          1704          14         162          96          22   \n",
       "114892  2012          1704          14         162          96          22   \n",
       "114893  2012          1704          14         162          96          22   \n",
       "114894  2012          1704          14         162          96          22   \n",
       "\n",
       "        lcDisposition  issueArea  results  \n",
       "0                   2          8        0  \n",
       "1                   2          8        1  \n",
       "2                   2          8        1  \n",
       "3                   2          8        1  \n",
       "4                   2          8        1  \n",
       "5                   2          8        1  \n",
       "6                   2          8        1  \n",
       "7                   2          8        1  \n",
       "8                   2          8        1  \n",
       "9                   2          1        0  \n",
       "10                  2          1        1  \n",
       "11                  2          1        0  \n",
       "12                  2          1        0  \n",
       "13                  2          1        0  \n",
       "14                  2          1        1  \n",
       "15                  2          1        0  \n",
       "16                  2          1        1  \n",
       "17                  2          1        0  \n",
       "18                  2          1        0  \n",
       "19                  2          1        1  \n",
       "20                  2          1        0  \n",
       "21                  2          1        0  \n",
       "22                  2          1        0  \n",
       "23                  2          1        1  \n",
       "24                  2          1        0  \n",
       "25                  2          1        1  \n",
       "26                  2          1        0  \n",
       "27                  2          1        0  \n",
       "28                  2          1        1  \n",
       "29                  2          1        0  \n",
       "...               ...        ...      ...  \n",
       "114865              5          2        1  \n",
       "114866              5          2        1  \n",
       "114867              5          2        1  \n",
       "114868              2          9        0  \n",
       "114869              2          9        0  \n",
       "114870              2          9        1  \n",
       "114871              2          9        1  \n",
       "114872              2          9        0  \n",
       "114873              2          9        0  \n",
       "114874              2          9        1  \n",
       "114875              2          9        1  \n",
       "114876              2          9        0  \n",
       "114877              2          1        1  \n",
       "114878              2          1        1  \n",
       "114879              2          1        1  \n",
       "114880              2          1        1  \n",
       "114881              2          1        1  \n",
       "114882              2          1        1  \n",
       "114883              2          1        1  \n",
       "114884              2          1        1  \n",
       "114885              2          1        1  \n",
       "114886              2          4        1  \n",
       "114887              2          4        1  \n",
       "114888              2          4        0  \n",
       "114889              2          4        1  \n",
       "114890              2          4        0  \n",
       "114891              2          4        0  \n",
       "114892              2          4        1  \n",
       "114893              2          4        0  \n",
       "114894              2          4        0  \n",
       "\n",
       "[114895 rows x 9 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsmalldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-07d253ae0c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/idzhang/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/idzhang/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/idzhang/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
